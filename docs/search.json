{
  "articles": [
    {
      "path": "about.html",
      "title": "QR",
      "author": [],
      "contents": "\r\n\r\n          \r\n          \r\n          \r\n          \r\n          ouR - academy\r\n          Home\r\n          About\r\n          \r\n          \r\n          \r\n          \r\n          R\r\n           \r\n          ▾\r\n          \r\n          \r\n          Programming\r\n          basics\r\n          apply family\r\n          functions\r\n          plot\r\n          text\r\n          date\r\n          Advance - R\r\n          dplyr\r\n          tidyr\r\n          ggplot2\r\n          advance-ggplot2\r\n          purrr\r\n          lubridate\r\n          stringr\r\n          \r\n          \r\n          \r\n          \r\n          R - Modeling\r\n           \r\n          ▾\r\n          \r\n          \r\n          tidymodels\r\n          caret\r\n          \r\n          \r\n          Shiny\r\n          \r\n          \r\n          \r\n          ☰\r\n          \r\n          \r\n      \r\n        \r\n          \r\n            QR\r\n          \r\n          \r\n            \r\n              This website is here to help you in understanding programming languages and its use for implementing data science, machine learning automation and to understand production using these tools. If you have found my work useful for your assignment completion, reporting in business, buy me a cup of coffee. To find my more work & for suggestions tap below.\r\n            \r\n            \r\n              This website is here to help you in understanding programming languages and its use for implementing data science, machine learning automation and to understand production using these tools. If you have found my work useful for your assignment completion, reporting in business, buy me a cup of coffee. To find my more work & for suggestions tap below.\r\n            \r\n          \r\n\r\n          \r\n            \r\n              \r\n                  \r\n                    \r\n                      YouTube\r\n                    \r\n                  \r\n                \r\n                                \r\n                  \r\n                    \r\n                      Vimeo\r\n                    \r\n                  \r\n                \r\n                                \r\n                  \r\n                    \r\n                      Linkedin\r\n                    \r\n                  \r\n                \r\n                                \r\n                  \r\n                    \r\n                      Email\r\n                    \r\n                  \r\n                \r\n                              \r\n          \r\n\r\n          \r\n            \r\n              \r\n                                \r\n                  \r\n                    YouTube\r\n                  \r\n                \r\n                                \r\n                  \r\n                    Vimeo\r\n                  \r\n                \r\n                                \r\n                  \r\n                    Linkedin\r\n                  \r\n                \r\n                                \r\n                  \r\n                    Email\r\n                  \r\n                \r\n                              \r\n            \r\n          \r\n        \r\n      \r\n    \r\n\r\n    \r\n    \r\n    ",
      "last_modified": "2022-02-16T13:00:28+05:30"
    },
    {
      "path": "advgg.html",
      "title": "ggplot-2",
      "author": [],
      "contents": "\r\n\r\n\r\nlibrary(ggplot2)\r\n\r\n\r\nset.seed(123)\r\n\r\ndf <- data.frame(\r\n  a = 1:100,\r\n  b = sample(letters[1:10], 100, replace = T),\r\n  c = c(rep('A',50), rep('B', 50)),\r\n  d = sample(100:150, 100, TRUE)\r\n)\r\n\r\n\r\n\r\n\r\n\r\nggplot(df, aes(b))+\r\n  geom_bar(aes(fill = b))+\r\n  facet_wrap(~c)\r\n\r\n\r\n\r\n\r\n\r\n\r\nggplot(df, aes(b))+\r\n  geom_bar(aes(fill = b))+\r\n  geom_point(data = df, mapping = aes(b, d, color = c))\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n",
      "last_modified": "2022-02-16T13:00:33+05:30"
    },
    {
      "path": "base.html",
      "title": "Quick Start With R",
      "author": [],
      "contents": "\r\nWhen I was a student, probably like you’re today, was confused about learning a programming language. Whether I will be able to learn it as a pro or it will provide me an opportunity of work. At the end of University days, R was introduced to me as a tool for data analysis. I really liked the idea of scripting and molding algorithms for fun, to create aesthetic graph etc.\r\nThis package contains the basic functions which let R function as a language: arithmetic, input/output, basic programming support, etc. Its contents are available through inheritance from any environment.\r\nFor a complete list of functions, use library(help = “base”). Everything in R is an object. Data types in R:\r\nBasics of R\r\nR has 6 basic data types. (General types)\r\n-   character: text written under '' or \"\".\r\n-   numeric  : numbers 0.1,1 or any number than can be expressed using dot.\r\n-   integer  : completed numbers such as 1,2,3..etc.\r\n-   logical  : TRUE, FALSE\r\n-   complex  : Imaginary numbers using 1i, 2i etc.\r\n-   Dates    : Special attention will be given to this.[Later]\r\nEvery word written under single quotation or double quotation mark are character/string for the machine. For example:\r\n\r\n\r\n# character type\r\nchar <- 'character'\r\ntypeof(char)\r\n\r\n\r\n[1] \"character\"\r\n\r\nclass(char)\r\n\r\n\r\n[1] \"character\"\r\n\r\nNumerical values are real number, which we generally use in our daily life.\r\n\r\n\r\n# numeric type\r\nnum <- 8.0\r\ntypeof(num)\r\n\r\n\r\n[1] \"double\"\r\n\r\nclass(num)\r\n\r\n\r\n[1] \"numeric\"\r\n\r\nIntegers are whole numbers which expressed without decimal values.\r\n\r\n\r\n# integer \r\nint <- 8L\r\ntypeof(int)\r\n\r\n\r\n[1] \"integer\"\r\n\r\nclass(int)\r\n\r\n\r\n[1] \"integer\"\r\n\r\nOne of the very important variable type is a logical type: TRUE and FALSE\r\n\r\n\r\n# logical\r\nLogical <- TRUE\r\ntypeof(Logical)\r\n\r\n\r\n[1] \"logical\"\r\n\r\nclass(Logical)\r\n\r\n\r\n[1] \"logical\"\r\n\r\nImaginary numbers which is used in high level scientific calculus.\r\n\r\n\r\n# complex number or imaginery number\r\nimaginery <- 8 + 4i\r\ntypeof(imaginery)\r\n\r\n\r\n[1] \"complex\"\r\n\r\nclass(imaginery)\r\n\r\n\r\n[1] \"complex\"\r\n\r\nR creates and works with 6 data structures:\r\n-   Atomic\r\n-   Vector\r\n-   Factors\r\n-   List\r\n-   Matrix\r\n-   Data Frame/tibble {modern for fast data manipulation, machine friendly}\r\nAtomic:\r\nany single data type (length of 1) in R is an atomic object.\r\n-  For e.g.\r\n\r\n\r\nx <- 'a'\r\nx <- 1\r\nx <- TRUE\r\nx <- 2+1i\r\n\r\n\r\n\r\nVector:\r\ncollection of same data types in an object.\r\n- For e.g.\r\n\r\n\r\nx <- c(1,2,3)\r\nx <- c('a','b','c')\r\nx <- c(TRUE,FALSE,F,T)  # F = FALSE, T = TRUE\r\nx <- c(1+1i,1-1i)\r\nx <- c(1L,2L,3L)\r\n\r\n\r\n\r\nMatrix\r\ncolumn bind of same length numeric, integer or complex vectors are called matrix.\r\n- For e.g.\r\n\r\n\r\na <- 1:5\r\nb <- 6:10\r\nc <- 11:15\r\nd <- 16:20\r\ne <- 21:25\r\n\r\nmtx <- cbind(a,b,c,d,e)\r\nmtx\r\n\r\n\r\n     a  b  c  d  e\r\n[1,] 1  6 11 16 21\r\n[2,] 2  7 12 17 22\r\n[3,] 3  8 13 18 23\r\n[4,] 4  9 14 19 24\r\n[5,] 5 10 15 20 25\r\n\r\nclass(mtx)\r\n\r\n\r\n[1] \"matrix\" \"array\" \r\n\r\nOr we can create using matrix function\r\n\r\n\r\nmtx <- matrix(1:25, 5, 5, byrow = F)\r\nmtx\r\n\r\n\r\n     [,1] [,2] [,3] [,4] [,5]\r\n[1,]    1    6   11   16   21\r\n[2,]    2    7   12   17   22\r\n[3,]    3    8   13   18   23\r\n[4,]    4    9   14   19   24\r\n[5,]    5   10   15   20   25\r\n\r\n\r\nNOTE: Matrix can only use numeric or integer types, This is why we have data frame in R.\r\n\r\nData Frame\r\nIt is a kind of matrix except it can handle every kind of vector inside it. This is what makes it more useful in real life.\r\n\r\n\r\nA <- c('a', 'b', 'c', 'd')\r\nB <- c(1L,2L,3L,4L)\r\nC <- seq(1,2,length.out = 4)\r\n\r\ndf <- data.frame(A, B,C)\r\ndf\r\n\r\n\r\n  A B        C\r\n1 a 1 1.000000\r\n2 b 2 1.333333\r\n3 c 3 1.666667\r\n4 d 4 2.000000\r\n\r\nclass(df)\r\n\r\n\r\n[1] \"data.frame\"\r\n\r\nNote tibble is fast and tidyverse friendly. Which you will learn later.\r\n\r\n\r\ndf <- tibble::tibble(\r\n  date = seq.Date(from = as.Date('2021-07-01'),to = as.Date('2021-07-10'), by = 1),\r\n  number = 1:10,\r\n  character = c('a','b','c','d','e','a','b','c','d','e') \r\n)\r\ndf\r\n\r\n\r\n# A tibble: 10 x 3\r\n   date       number character\r\n   <date>      <int> <chr>    \r\n 1 2021-07-01      1 a        \r\n 2 2021-07-02      2 b        \r\n 3 2021-07-03      3 c        \r\n 4 2021-07-04      4 d        \r\n 5 2021-07-05      5 e        \r\n 6 2021-07-06      6 a        \r\n 7 2021-07-07      7 b        \r\n 8 2021-07-08      8 c        \r\n 9 2021-07-09      9 d        \r\n10 2021-07-10     10 e        \r\n\r\nclass(df)\r\n\r\n\r\n[1] \"tbl_df\"     \"tbl\"        \"data.frame\"\r\n\r\nR operators\r\n-  '=' and '<-'{left} or '->'{right} are both used to assign values to object.\r\n-  Since R is mathematical friendly language one can use R as a calculator as well, for scientific as well.\r\n-  ['+', '-', '*', '/', 'log', 'exp' etc.]\r\n-  Mathematical operators\r\n-  ['>', '<', '!', '>=', '<=','==']\r\n\r\nNote: ‘==’ is not ‘=’, latter is used to assign values in R. And ‘!’ can be used in any line where we have to tell are e.g. not equal to or not true.\r\n\r\nmatrix operators are:\r\n-  ['%%', '%/%','^', '%*%']\r\n%% : Use to find remainder\r\n\r\n\r\n46%%5\r\n\r\n\r\n[1] 1\r\n\r\n%/% : Use to find quotient\r\n\r\n\r\n46%/%4\r\n\r\n\r\n[1] 11\r\n\r\n^ : Power of a value\r\n\r\n\r\n4^3\r\n\r\n\r\n[1] 64\r\n\r\n**%*%** : Matrix Multiplication\r\n\r\n\r\na <- matrix(1:9,3,3)\r\nb <- matrix(c(1,2,3),3,1)\r\n\r\na%*%b\r\n\r\n\r\n     [,1]\r\n[1,]   30\r\n[2,]   36\r\n[3,]   42\r\n\r\nBasic Statistics\r\n\r\n\r\n# Central tendancy parameter\r\nx <- rnorm(200) + 125\r\n\r\nmean(x)\r\n\r\n\r\n[1] 125.0866\r\n\r\nmedian(x)\r\n\r\n\r\n[1] 125.0312\r\n\r\n# Variability parameters\r\nvar(x)\r\n\r\n\r\n[1] 0.9506728\r\n\r\nsd(x)\r\n\r\n\r\n[1] 0.9750245\r\n\r\nshapiro.test(x)\r\n\r\n\r\n\r\n    Shapiro-Wilk normality test\r\n\r\ndata:  x\r\nW = 0.98905, p-value = 0.1295\r\n\r\n\r\n\r\n\r\n",
      "last_modified": "2022-02-16T13:00:36+05:30"
    },
    {
      "path": "base_text.html",
      "title": "Basic Text Operation",
      "author": [],
      "contents": "\r\nInternet boom has led the massive increase in the unstructured data which is a text, image, audio and video image. So does the demand for the professionals who can analyse these data effectively. Unfortunately very few users knows that R has surprisingly good interface or script for dealing with text data. Which we will go through one by one. Hope you will like it to the moon.\r\nBasics of strings\r\nHow to count number of characters\r\n\r\n\r\nalphabets <- 'abcdefghijklmnopqrstuvwxyz'\r\nnchar(alphabets)\r\n\r\n\r\n[1] 26\r\n\r\nnchar function counts space as well when we use it for a paragraph.\r\n\r\n\r\nchar <- 'the first lesson'\r\n\r\nnchar(char)\r\n\r\n\r\n[1] 16\r\n\r\nExtracting first three characters\r\n\r\n\r\nsubstring(alphabets, 1, 3)\r\n\r\n\r\n[1] \"abc\"\r\n\r\nExtracting last three characters\r\n\r\n\r\nlast <- 3\r\nsubstring(alphabets, nchar(alphabets) - last + 1)\r\n\r\n\r\n[1] \"xyz\"\r\n\r\nFind last 3 strings in small letters for n number of words\r\n\r\n\r\nname <- c('abaiCED', 'eddaDed', 'zeAdEGE', 'adedCeD', 'adcdecED')\r\n\r\n\r\n\r\nfor(n in 1:length(name)) {\r\n    nn = tolower(name[n])\r\n    last = 3\r\n    nl = substring(nn, nchar(nn)- last + 1, nchar(nn))\r\n    print(\r\n        ifelse(nl == 'ced', TRUE, FALSE)\r\n    )\r\n}\r\n\r\n\r\n[1] TRUE\r\n[1] FALSE\r\n[1] FALSE\r\n[1] TRUE\r\n[1] TRUE\r\n\r\nCoversion from Upper to Lower\r\n\r\n\r\na <- 'ABCDEF'\r\n\r\ntolower(a)\r\n\r\n\r\n[1] \"abcdef\"\r\n\r\nCoversion from Lower to Upper\r\n\r\n\r\na <- 'abcdef'\r\n\r\ntoupper(a)\r\n\r\n\r\n[1] \"ABCDEF\"\r\n\r\nsprintf function\r\nThe function follows C-Style string formatting commands for coding.\r\n\r\n\r\nsprintf('%s earns %1.0f', 'Shyam', 125.5)\r\n\r\n\r\n[1] \"Shyam earns 126\"\r\n\r\n\r\n\r\ncity <- c(\"Mumbai\", 'Delhi', 'Chennai')\r\n\r\npop <- c(25.5, 18.5, 12.7)\r\n\r\nsprintf('%s has population of %1.0f per km.', city, pop)\r\n\r\n\r\n[1] \"Mumbai has population of 26 per km.\" \r\n[2] \"Delhi has population of 18 per km.\"  \r\n[3] \"Chennai has population of 13 per km.\"\r\n\r\n\r\n\r\nsprintf(\"%f\", log(10))\r\n\r\n\r\n[1] \"2.302585\"\r\n\r\nsprintf(\"%.3f\", log(10))\r\n\r\n\r\n[1] \"2.303\"\r\n\r\nsprintf(\"%1.0f\", log(10))\r\n\r\n\r\n[1] \"2\"\r\n\r\nsprintf(\"%5.1f\", log(10))\r\n\r\n\r\n[1] \"  2.3\"\r\n\r\nsprintf(\"%05.1f\", log(10))\r\n\r\n\r\n[1] \"002.3\"\r\n\r\nsprintf(\"%+f\", log(10))\r\n\r\n\r\n[1] \"+2.302585\"\r\n\r\nsprintf(\"% f\", log(10))\r\n\r\n\r\n[1] \" 2.302585\"\r\n\r\nsprintf(\"%-10f\", log(10)) # left justified\r\n\r\n\r\n[1] \"2.302585  \"\r\n\r\nsprintf(\"%e\", log(10))\r\n\r\n\r\n[1] \"2.302585e+00\"\r\n\r\nsprintf(\"%E\", log(10))\r\n\r\n\r\n[1] \"2.302585E+00\"\r\n\r\nsprintf(\"%g\", log(10))\r\n\r\n\r\n[1] \"2.30259\"\r\n\r\nsprintf(\"%g\",   1e6 * log(10)) # -> exponential\r\n\r\n\r\n[1] \"2.30259e+06\"\r\n\r\nsprintf(\"%.9g\", 1e6 * log(10)) # -> \"fixed\"\r\n\r\n\r\n[1] \"2302585.09\"\r\n\r\nsprintf(\"%G\", 1e-6 * log(10))\r\n\r\n\r\n[1] \"2.30259E-06\"\r\n\r\nFunctions are:\r\n1. paste/paste0\r\n2. strsplit\r\n3. substr \r\n4. grep\r\n5. nchar\r\n6. and regex function.\r\nNote: There are more functions which deals with Text manipulation and processing, here we’re only going through the most used functions.\r\npaste0/paste function\r\nIt is one of the most fascinating function that R has. Personally I find it really helpful. After a little time, you will see it why:\r\nHere we go:\r\n\r\n\r\npaste('A', 'B', 'C', sep = '')\r\n\r\n\r\n[1] \"ABC\"\r\n\r\nPaste has 2 major arguments one is separator and another is number of ‘strings’ which we want to tie together. As in the above case we want a, b and c to tie together as ABC, since separator by default is ‘space’. That’s why I have wrote it exclusively as ’’.\r\n\r\n\r\na <- c(\"Mumbai\", 'Delhi', 'Chennai')\r\nb <- c(' Is Financial Capital of India', ' Official capital city of India', ' fascinating Capital city  of Tamil-Nadu')\r\n\r\npaste0(a, b, collapse = \". \")\r\n\r\n\r\n[1] \"Mumbai Is Financial Capital of India. Delhi Official capital city of India. Chennai fascinating Capital city  of Tamil-Nadu\"\r\n\r\nHow easy concatenation in R using paste function is. However I often find a way to comment.\r\nLastly, One atom object with a vector\r\n\r\n\r\npaste0('I', c(' am a boy', ' like to dance', ' can sing also'))\r\n\r\n\r\n[1] \"I am a boy\"      \"I like to dance\" \"I can sing also\"\r\n\r\nstrsplit function\r\nopposite of paste function. Lets see how!\r\n\r\n\r\na <- 'He is a nice boy. He can join us on monday'\r\n\r\n\r\nstrsplit(a, fixed = T, split = '.')\r\n\r\n\r\n[[1]]\r\n[1] \"He is a nice boy\"          \" He can join us on monday\"\r\n\r\nsubstr/substring function\r\n\r\n\r\na <- 'welcome'\r\n\r\nsubstr(a, 1, 3)\r\n\r\n\r\n[1] \"wel\"\r\n\r\nsubstr(a, 4, 8) <- \"-off\"\r\n\r\nsubstr(a, 4, 8) == \"come\"\r\n\r\n\r\n[1] FALSE\r\n\r\nprint(a)\r\n\r\n\r\n[1] \"wel-off\"\r\n\r\nNOTE: We have value argument in substr function which asks for if a particular value needed to be recycled\r\n\r\n\r\nsubstr(rep('edcba',4), 1:4, 2:5)\r\n\r\n\r\n[1] \"ed\" \"dc\" \"cb\" \"ba\"\r\n\r\nRegular Expression\r\ngrep/grepl\r\n\r\n\r\nvec <- c('Neera', 'Veera', 'Jeera', 'Eshi', 'Nishi', 'Meesha')\r\n\r\ngrep('ee', vec)\r\n\r\n\r\n[1] 1 2 3 6\r\n\r\ngrep('ee', vec, value = T)\r\n\r\n\r\n[1] \"Neera\"  \"Veera\"  \"Jeera\"  \"Meesha\"\r\n\r\ngrepl('ee', vec)\r\n\r\n\r\n[1]  TRUE  TRUE  TRUE FALSE FALSE  TRUE\r\n\r\nregexpr/gregexpr/regexec\r\n\r\n\r\nregexpr('ee', vec)\r\n\r\n\r\n[1]  2  2  2 -1 -1  2\r\nattr(,\"match.length\")\r\n[1]  2  2  2 -1 -1  2\r\nattr(,\"index.type\")\r\n[1] \"chars\"\r\nattr(,\"useBytes\")\r\n[1] TRUE\r\n\r\nregexec('ee', vec)\r\n\r\n\r\n[[1]]\r\n[1] 2\r\nattr(,\"match.length\")\r\n[1] 2\r\nattr(,\"index.type\")\r\n[1] \"chars\"\r\nattr(,\"useBytes\")\r\n[1] TRUE\r\n\r\n[[2]]\r\n[1] 2\r\nattr(,\"match.length\")\r\n[1] 2\r\nattr(,\"index.type\")\r\n[1] \"chars\"\r\nattr(,\"useBytes\")\r\n[1] TRUE\r\n\r\n[[3]]\r\n[1] 2\r\nattr(,\"match.length\")\r\n[1] 2\r\nattr(,\"index.type\")\r\n[1] \"chars\"\r\nattr(,\"useBytes\")\r\n[1] TRUE\r\n\r\n[[4]]\r\n[1] -1\r\nattr(,\"match.length\")\r\n[1] -1\r\nattr(,\"index.type\")\r\n[1] \"chars\"\r\nattr(,\"useBytes\")\r\n[1] TRUE\r\n\r\n[[5]]\r\n[1] -1\r\nattr(,\"match.length\")\r\n[1] -1\r\nattr(,\"index.type\")\r\n[1] \"chars\"\r\nattr(,\"useBytes\")\r\n[1] TRUE\r\n\r\n[[6]]\r\n[1] 2\r\nattr(,\"match.length\")\r\n[1] 2\r\nattr(,\"index.type\")\r\n[1] \"chars\"\r\nattr(,\"useBytes\")\r\n[1] TRUE\r\n\r\ngregexpr('ee', vec)\r\n\r\n\r\n[[1]]\r\n[1] 2\r\nattr(,\"match.length\")\r\n[1] 2\r\nattr(,\"index.type\")\r\n[1] \"chars\"\r\nattr(,\"useBytes\")\r\n[1] TRUE\r\n\r\n[[2]]\r\n[1] 2\r\nattr(,\"match.length\")\r\n[1] 2\r\nattr(,\"index.type\")\r\n[1] \"chars\"\r\nattr(,\"useBytes\")\r\n[1] TRUE\r\n\r\n[[3]]\r\n[1] 2\r\nattr(,\"match.length\")\r\n[1] 2\r\nattr(,\"index.type\")\r\n[1] \"chars\"\r\nattr(,\"useBytes\")\r\n[1] TRUE\r\n\r\n[[4]]\r\n[1] -1\r\nattr(,\"match.length\")\r\n[1] -1\r\nattr(,\"index.type\")\r\n[1] \"chars\"\r\nattr(,\"useBytes\")\r\n[1] TRUE\r\n\r\n[[5]]\r\n[1] -1\r\nattr(,\"match.length\")\r\n[1] -1\r\nattr(,\"index.type\")\r\n[1] \"chars\"\r\nattr(,\"useBytes\")\r\n[1] TRUE\r\n\r\n[[6]]\r\n[1] 2\r\nattr(,\"match.length\")\r\n[1] 2\r\nattr(,\"index.type\")\r\n[1] \"chars\"\r\nattr(,\"useBytes\")\r\n[1] TRUE\r\n\r\ngregexec('ee', vec)\r\n\r\n\r\n[[1]]\r\n     [,1]\r\n[1,]    2\r\nattr(,\"match.length\")\r\n     [,1]\r\n[1,]    2\r\nattr(,\"useBytes\")\r\n[1] TRUE\r\nattr(,\"index.type\")\r\n[1] \"chars\"\r\n\r\n[[2]]\r\n     [,1]\r\n[1,]    2\r\nattr(,\"match.length\")\r\n     [,1]\r\n[1,]    2\r\nattr(,\"useBytes\")\r\n[1] TRUE\r\nattr(,\"index.type\")\r\n[1] \"chars\"\r\n\r\n[[3]]\r\n     [,1]\r\n[1,]    2\r\nattr(,\"match.length\")\r\n     [,1]\r\n[1,]    2\r\nattr(,\"useBytes\")\r\n[1] TRUE\r\nattr(,\"index.type\")\r\n[1] \"chars\"\r\n\r\n[[4]]\r\n[1] -1\r\nattr(,\"match.length\")\r\n[1] -1\r\nattr(,\"index.type\")\r\n[1] \"chars\"\r\nattr(,\"useBytes\")\r\n[1] TRUE\r\n\r\n[[5]]\r\n[1] -1\r\nattr(,\"match.length\")\r\n[1] -1\r\nattr(,\"index.type\")\r\n[1] \"chars\"\r\nattr(,\"useBytes\")\r\n[1] TRUE\r\n\r\n[[6]]\r\n     [,1]\r\n[1,]    2\r\nattr(,\"match.length\")\r\n     [,1]\r\n[1,]    2\r\nattr(,\"useBytes\")\r\n[1] TRUE\r\nattr(,\"index.type\")\r\n[1] \"chars\"\r\n\r\n\r\n\r\n\r\n",
      "last_modified": "2022-02-16T13:00:39+05:30"
    },
    {
      "path": "caret.html",
      "title": "CARET",
      "author": [],
      "contents": "\r\nClassification And REgression Training\r\n  -  data splitting\r\n  -  pre-processing\r\n  -  feature selection\r\n  -  model tuning using re-sampling\r\n  -  variable importance estimation\r\n  \r\nFirstly, Install the package using commands:\r\n_install.packages(\"caret\")_\r\nLIBRARIES TO USE\r\n\r\n\r\nsuppressMessages(library(dplyr))\r\nsuppressMessages(library(ggplot2))\r\nsuppressMessages(library(caret))\r\nsuppressMessages(library(e1071))\r\nsuppressMessages(library(gbm))\r\nsuppressMessages(library(mlbench))\r\nsuppressMessages(library(randomForest))\r\nsuppressMessages(library(neuralnet))\r\nsuppressMessages(library(pROC))\r\nsuppressMessages(library(gt))\r\n\r\n\r\n\r\nCARET currently have 239 models included in latest version of caret {6.0.88}. Please make yourself ready for a thriller.\r\n\r\n  [1] \"ada\"                 \"AdaBag\"             \r\n  [3] \"AdaBoost.M1\"         \"adaboost\"           \r\n  [5] \"amdai\"               \"ANFIS\"              \r\n  [7] \"avNNet\"              \"awnb\"               \r\n  [9] \"awtan\"               \"bag\"                \r\n [11] \"bagEarth\"            \"bagEarthGCV\"        \r\n [13] \"bagFDA\"              \"bagFDAGCV\"          \r\n [15] \"bam\"                 \"bartMachine\"        \r\n [17] \"bayesglm\"            \"binda\"              \r\n [19] \"blackboost\"          \"blasso\"             \r\n [21] \"blassoAveraged\"      \"bridge\"             \r\n [23] \"brnn\"                \"BstLm\"              \r\n [25] \"bstSm\"               \"bstTree\"            \r\n [27] \"C5.0\"                \"C5.0Cost\"           \r\n [29] \"C5.0Rules\"           \"C5.0Tree\"           \r\n [31] \"cforest\"             \"chaid\"              \r\n [33] \"CSimca\"              \"ctree\"              \r\n [35] \"ctree2\"              \"cubist\"             \r\n [37] \"dda\"                 \"deepboost\"          \r\n [39] \"DENFIS\"              \"dnn\"                \r\n [41] \"dwdLinear\"           \"dwdPoly\"            \r\n [43] \"dwdRadial\"           \"earth\"              \r\n [45] \"elm\"                 \"enet\"               \r\n [47] \"evtree\"              \"extraTrees\"         \r\n [49] \"fda\"                 \"FH.GBML\"            \r\n [51] \"FIR.DM\"              \"foba\"               \r\n [53] \"FRBCS.CHI\"           \"FRBCS.W\"            \r\n [55] \"FS.HGD\"              \"gam\"                \r\n [57] \"gamboost\"            \"gamLoess\"           \r\n [59] \"gamSpline\"           \"gaussprLinear\"      \r\n [61] \"gaussprPoly\"         \"gaussprRadial\"      \r\n [63] \"gbm_h2o\"             \"gbm\"                \r\n [65] \"gcvEarth\"            \"GFS.FR.MOGUL\"       \r\n [67] \"GFS.LT.RS\"           \"GFS.THRIFT\"         \r\n [69] \"glm.nb\"              \"glm\"                \r\n [71] \"glmboost\"            \"glmnet_h2o\"         \r\n [73] \"glmnet\"              \"glmStepAIC\"         \r\n [75] \"gpls\"                \"hda\"                \r\n [77] \"hdda\"                \"hdrda\"              \r\n [79] \"HYFIS\"               \"icr\"                \r\n [81] \"J48\"                 \"JRip\"               \r\n [83] \"kernelpls\"           \"kknn\"               \r\n [85] \"knn\"                 \"krlsPoly\"           \r\n [87] \"krlsRadial\"          \"lars\"               \r\n [89] \"lars2\"               \"lasso\"              \r\n [91] \"lda\"                 \"lda2\"               \r\n [93] \"leapBackward\"        \"leapForward\"        \r\n [95] \"leapSeq\"             \"Linda\"              \r\n [97] \"lm\"                  \"lmStepAIC\"          \r\n [99] \"LMT\"                 \"loclda\"             \r\n[101] \"logicBag\"            \"LogitBoost\"         \r\n[103] \"logreg\"              \"lssvmLinear\"        \r\n[105] \"lssvmPoly\"           \"lssvmRadial\"        \r\n[107] \"lvq\"                 \"M5\"                 \r\n[109] \"M5Rules\"             \"manb\"               \r\n[111] \"mda\"                 \"Mlda\"               \r\n[113] \"mlp\"                 \"mlpKerasDecay\"      \r\n[115] \"mlpKerasDecayCost\"   \"mlpKerasDropout\"    \r\n[117] \"mlpKerasDropoutCost\" \"mlpML\"              \r\n[119] \"mlpSGD\"              \"mlpWeightDecay\"     \r\n[121] \"mlpWeightDecayML\"    \"monmlp\"             \r\n[123] \"msaenet\"             \"multinom\"           \r\n[125] \"mxnet\"               \"mxnetAdam\"          \r\n[127] \"naive_bayes\"         \"nb\"                 \r\n[129] \"nbDiscrete\"          \"nbSearch\"           \r\n[131] \"neuralnet\"           \"nnet\"               \r\n[133] \"nnls\"                \"nodeHarvest\"        \r\n[135] \"null\"                \"OneR\"               \r\n[137] \"ordinalNet\"          \"ordinalRF\"          \r\n[139] \"ORFlog\"              \"ORFpls\"             \r\n[141] \"ORFridge\"            \"ORFsvm\"             \r\n[143] \"ownn\"                \"pam\"                \r\n[145] \"parRF\"               \"PART\"               \r\n[147] \"partDSA\"             \"pcaNNet\"            \r\n[149] \"pcr\"                 \"pda\"                \r\n[151] \"pda2\"                \"penalized\"          \r\n[153] \"PenalizedLDA\"        \"plr\"                \r\n[155] \"pls\"                 \"plsRglm\"            \r\n[157] \"polr\"                \"ppr\"                \r\n[159] \"pre\"                 \"PRIM\"               \r\n[161] \"protoclass\"          \"qda\"                \r\n[163] \"QdaCov\"              \"qrf\"                \r\n[165] \"qrnn\"                \"randomGLM\"          \r\n[167] \"ranger\"              \"rbf\"                \r\n[169] \"rbfDDA\"              \"Rborist\"            \r\n[171] \"rda\"                 \"regLogistic\"        \r\n[173] \"relaxo\"              \"rf\"                 \r\n[175] \"rFerns\"              \"RFlda\"              \r\n[177] \"rfRules\"             \"ridge\"              \r\n[179] \"rlda\"                \"rlm\"                \r\n[181] \"rmda\"                \"rocc\"               \r\n[183] \"rotationForest\"      \"rotationForestCp\"   \r\n[185] \"rpart\"               \"rpart1SE\"           \r\n[187] \"rpart2\"              \"rpartCost\"          \r\n[189] \"rpartScore\"          \"rqlasso\"            \r\n[191] \"rqnc\"                \"RRF\"                \r\n[193] \"RRFglobal\"           \"rrlda\"              \r\n[195] \"RSimca\"              \"rvmLinear\"          \r\n[197] \"rvmPoly\"             \"rvmRadial\"          \r\n[199] \"SBC\"                 \"sda\"                \r\n[201] \"sdwd\"                \"simpls\"             \r\n[203] \"SLAVE\"               \"slda\"               \r\n[205] \"smda\"                \"snn\"                \r\n[207] \"sparseLDA\"           \"spikeslab\"          \r\n[209] \"spls\"                \"stepLDA\"            \r\n[211] \"stepQDA\"             \"superpc\"            \r\n[213] \"svmBoundrangeString\" \"svmExpoString\"      \r\n[215] \"svmLinear\"           \"svmLinear2\"         \r\n[217] \"svmLinear3\"          \"svmLinearWeights\"   \r\n[219] \"svmLinearWeights2\"   \"svmPoly\"            \r\n[221] \"svmRadial\"           \"svmRadialCost\"      \r\n[223] \"svmRadialSigma\"      \"svmRadialWeights\"   \r\n[225] \"svmSpectrumString\"   \"tan\"                \r\n[227] \"tanSearch\"           \"treebag\"            \r\n[229] \"vbmpRadial\"          \"vglmAdjCat\"         \r\n[231] \"vglmContRatio\"       \"vglmCumulative\"     \r\n[233] \"widekernelpls\"       \"WM\"                 \r\n[235] \"wsrf\"                \"xgbDART\"            \r\n[237] \"xgbLinear\"           \"xgbTree\"            \r\n[239] \"xyf\"                \r\n\r\nAn auto-insurance company is revamping its pricing model. The analyst developing the new price model believes that the best approach is to develop 2 models: one for customers who are likely to file an insurance claim within the first year of their contract and another one for all other customers. The analyst has prepared a clean dataset consisting of 10,000 customers and 10 engineered features which capture driving behavior. The data has already been pre-processed for you (i.e., no missing data, no outliers, data is scaled, no correlated features, and the classes are fairly balanced). The data is contained in claim_prediction.csv , where CLAIM = 1 means the customer filed a claim in the first year and CLAIM = 0 means the customer did not. Develop a model to predict if customers will file a claim in their first year based on their driving behavior. In addition to submitting your code, use comments to explain the decisions you made and how well you expect this model to perform on new data from a similar customer pool (and why).\r\nNote that you are being evaluated on your model building and validation workflow, rather than on the complexity of your solution.\r\nIMPORTING DATA FROM MACHINE\r\n\r\n\r\ndb_file <- readRDS('data/db_file.RDS')\r\n\r\nnames(db_file) <- tolower(names(db_file))\r\ndb_file$claim <- factor(db_file$claim, levels = c(0,1))\r\n\r\n\r\n\r\nBASIC SUMMARY REPORT\r\n\r\n\r\nsummary(db_file)\r\n\r\n\r\n     eaddc             eafxa             fddbc          \r\n Min.   :-8.6810   Min.   :-9.2100   Min.   :-7.809085  \r\n 1st Qu.:-2.3760   1st Qu.:-2.2884   1st Qu.:-1.605232  \r\n Median :-0.9240   Median :-0.7959   Median :-0.054862  \r\n Mean   :-0.7781   Mean   :-0.7449   Mean   : 0.005933  \r\n 3rd Qu.: 0.7501   3rd Qu.: 0.7956   3rd Qu.: 1.572018  \r\n Max.   : 8.2273   Max.   : 7.0404   Max.   : 9.119290  \r\n     afdda             axcxa              excce        \r\n Min.   :-6.6279   Min.   :-9.93688   Min.   :-8.8114  \r\n 1st Qu.:-0.6471   1st Qu.:-1.67694   1st Qu.:-0.8607  \r\n Median : 0.8958   Median :-0.03197   Median : 0.8303  \r\n Mean   : 0.7641   Mean   :-0.03730   Mean   : 0.7473  \r\n 3rd Qu.: 2.2121   3rd Qu.: 1.59999   3rd Qu.: 2.4207  \r\n Max.   : 9.2032   Max.   : 7.25691   Max.   : 9.4842  \r\n     fbxfc              dffec             cexae         \r\n Min.   :-7.57842   Min.   :-7.9576   Min.   :-8.82289  \r\n 1st Qu.:-1.64236   1st Qu.:-2.2499   1st Qu.:-1.64179  \r\n Median : 0.06361   Median :-0.9137   Median : 0.14379  \r\n Mean   : 0.02767   Mean   :-0.7546   Mean   :-0.01217  \r\n 3rd Qu.: 1.68036   3rd Qu.: 0.6417   3rd Qu.: 1.67551  \r\n Max.   : 8.22503   Max.   : 8.4134   Max.   : 8.26862  \r\n     bbadx         claim   \r\n Min.   :-8.3827   0:5052  \r\n 1st Qu.:-0.7139   1:4948  \r\n Median : 0.8871           \r\n Mean   : 0.7248           \r\n 3rd Qu.: 2.2628           \r\n Max.   : 8.0424           \r\n\r\nSPLITTING DATA\r\nData partition using caret package createPartition function. It simply uses index numbers to partition a data frame / data tibble.\r\n\r\n\r\nset.seed(114)\r\n\r\nindex <- createDataPartition(db_file$claim, p = 0.8, list = FALSE)\r\n\r\ntrain <- db_file[index, ]\r\n\r\ntest <- db_file[-index, ]\r\n\r\n\r\n\r\nCROSS VALIDATION METHOD\r\n\r\n\r\nset.seed(432)\r\ntc <- trainControl(method = 'cv', number = 10)\r\n\r\n\r\n\r\nLDA {Linear Discriminant Analysis}\r\n\r\n\r\nlda <- train(\r\n  claim ~ .,\r\n  data = train,\r\n  method = 'lda',\r\n  metric = 'Accuracy',\r\n  trcontrol = tc\r\n)\r\n\r\n\r\nlda\r\n\r\n\r\nLinear Discriminant Analysis \r\n\r\n8001 samples\r\n  10 predictor\r\n   2 classes: '0', '1' \r\n\r\nNo pre-processing\r\nResampling: Bootstrapped (25 reps) \r\nSummary of sample sizes: 8001, 8001, 8001, 8001, 8001, 8001, ... \r\nResampling results:\r\n\r\n  Accuracy   Kappa    \r\n  0.8189057  0.6376787\r\n\r\n\r\n\r\nldapred <- predict(lda, train)\r\n\r\nlda_params <- confusionMatrix(train$claim, ldapred, positive = '1')\r\n\r\n\r\nlda_accuracy <- lda_params$overall[1]\r\nlda_kappa <- lda_params$overall[2]\r\nlda_accuracy_lower <- lda_params$overall[3]\r\nlda_accuracy_upper <- lda_params$overall[4]\r\n\r\n\r\nldaprob <- predict(lda, train, type = 'prob')\r\n\r\n\r\nlda_sentivity <- lda_params$byClass[1]\r\nlda_specificity <- lda_params$byClass[2]\r\nlda_precision <- lda_params$byClass[5]\r\nlda_recall <- lda_params$byClass[6]\r\nlda_f1 <- lda_params$byClass[7]\r\nlda_prevalence <- lda_params$byClass[8]\r\n\r\n\r\n\r\nQDA {Quadratic Discriminant Analysis}\r\n\r\n\r\nqda <- train(\r\n  claim ~ .,\r\n  data = train,\r\n  method = 'qda',\r\n  trcontrol = tc\r\n) \r\n\r\n\r\nprint(qda)\r\n\r\n\r\nQuadratic Discriminant Analysis \r\n\r\n8001 samples\r\n  10 predictor\r\n   2 classes: '0', '1' \r\n\r\nNo pre-processing\r\nResampling: Bootstrapped (25 reps) \r\nSummary of sample sizes: 8001, 8001, 8001, 8001, 8001, 8001, ... \r\nResampling results:\r\n\r\n  Accuracy   Kappa    \r\n  0.8762166  0.7524044\r\n\r\n\r\n\r\nqdapred <- predict(qda, train)\r\n\r\nqda_params <- confusionMatrix(train$claim, qdapred, positive = '1')\r\n\r\n\r\nqda_accuracy <- qda_params$overall[1]\r\nqda_kappa <- qda_params$overall[2]\r\nqda_accuracy_lower <- qda_params$overall[3]\r\nqda_accuracy_upper <- qda_params$overall[4]\r\n\r\n\r\nqdaprob <- predict(qda, train, type = 'prob')\r\n\r\n\r\nqda_sentivity <- qda_params$byClass[1]\r\nqda_specificity <- qda_params$byClass[2]\r\nqda_precision <- qda_params$byClass[5]\r\nqda_recall <- qda_params$byClass[6]\r\nqda_f1 <- qda_params$byClass[7]\r\nqda_prevalence <- qda_params$byClass[8]\r\n\r\n\r\n\r\nGLM {Logistic Regression}\r\n\r\n\r\nlogit <- train(\r\n  claim ~ .,\r\n  data = train,\r\n  method = 'glm', family = 'binomial',\r\n  trControl = tc\r\n)\r\n\r\nprint(logit)\r\n\r\n\r\nGeneralized Linear Model \r\n\r\n8001 samples\r\n  10 predictor\r\n   2 classes: '0', '1' \r\n\r\nNo pre-processing\r\nResampling: Cross-Validated (10 fold) \r\nSummary of sample sizes: 7201, 7200, 7201, 7202, 7201, 7201, ... \r\nResampling results:\r\n\r\n  Accuracy   Kappa    \r\n  0.8195232  0.6389814\r\n\r\n\r\n\r\nlogitpred <- predict(logit, train)\r\n\r\nlogit_params <- confusionMatrix(train$claim, logitpred, positive = '1')\r\n\r\n\r\nlogit_accuracy <- logit_params$overall[1]\r\nlogit_kappa <- logit_params$overall[2]\r\nlogit_accuracy_lower <- logit_params$overall[3]\r\nlogit_accuracy_upper <- logit_params$overall[4]\r\n\r\n\r\nlogitprob <- predict(logit, train, type = 'prob')\r\n\r\nlogit_sentivity <- logit_params$byClass[1]\r\nlogit_specificity <- logit_params$byClass[2]\r\nlogit_precision <- logit_params$byClass[5]\r\nlogit_recall <- logit_params$byClass[6]\r\nlogit_f1 <- logit_params$byClass[7]\r\nlogit_prevalence <- logit_params$byClass[8]\r\n\r\n\r\n\r\nCART {Classification & Regression Tree}\r\n\r\n\r\ntree <- train(\r\n  claim ~ ., \r\n  data = train,\r\n  method = 'rpart',\r\n  trControl = tc\r\n  )\r\n\r\n\r\ntree\r\n\r\n\r\nCART \r\n\r\n8001 samples\r\n  10 predictor\r\n   2 classes: '0', '1' \r\n\r\nNo pre-processing\r\nResampling: Cross-Validated (10 fold) \r\nSummary of sample sizes: 7201, 7201, 7200, 7200, 7201, 7201, ... \r\nResampling results across tuning parameters:\r\n\r\n  cp          Accuracy   Kappa    \r\n  0.02323819  0.7702739  0.5403422\r\n  0.02930033  0.7542793  0.5083809\r\n  0.49760040  0.6210609  0.2371210\r\n\r\nAccuracy was used to select the optimal model using the\r\n largest value.\r\nThe final value used for the model was cp = 0.02323819.\r\n\r\n\r\n\r\ntreepred <- predict(tree, train)\r\n\r\ntree_params <- confusionMatrix(train$claim, treepred, positive = '1')\r\n\r\n\r\ntree_accuracy <- tree_params$overall[1]\r\ntree_kappa <- tree_params$overall[2]\r\ntree_accuracy_lower <- tree_params$overall[3]\r\ntree_accuracy_upper <- tree_params$overall[4]\r\n\r\n\r\ntreeprob <- predict(tree, train, type = 'prob')\r\n\r\ntree_sentivity <- tree_params$byClass[1]\r\ntree_specificity <- tree_params$byClass[2]\r\ntree_precision <- tree_params$byClass[5]\r\ntree_recall <- tree_params$byClass[6]\r\ntree_f1 <- tree_params$byClass[7]\r\ntree_prevalence <- tree_params$byClass[8]\r\n\r\n\r\n\r\nRANDOM FOREST\r\nrandomForest implements Breiman’s random forest algorithm (based on Breiman and Cutler’s original Fortran code) for classification and regression.\r\nHere are the definitions of the variable importance measures.\r\nThe first measure is computed from permuting OOB data: For each tree, the prediction error on the out-of-bag portion of the data is recorded (error rate for classification, MSE for regression). Then the same is done after permuting each predictor variable. The difference between the two are then averaged over all trees, and normalized by the standard deviation of the differences. If the standard deviation of the differences is equal to 0 for a variable, the division is not done (but the average is almost always equal to 0 in that case).\r\nThe second measure is the total decrease in node impurities from splitting on the variable, averaged over all trees. For classification, the node impurity is measured by the Gini index. For regression, it is measured by residual sum of squares.\r\n\r\n\r\nset.seed(126)\r\n# grid <- expand.grid(\r\n#                     interaction.depth = c(1, 3, 5, 7),\r\n#                     ntrees = c(100, 150, 500)\r\n#                   )\r\n\r\nsystem.time(\r\n  rf <- train(\r\n    claim ~ .,\r\n    data = train,\r\n    method = 'rf',\r\n    trControl = tc,\r\n    tuneLength = 5\r\n    #tuneGrid = grid\r\n  )\r\n)\r\n\r\n\r\n   user  system elapsed \r\n 307.86   11.80  349.33 \r\n\r\nrf\r\n\r\n\r\nRandom Forest \r\n\r\n8001 samples\r\n  10 predictor\r\n   2 classes: '0', '1' \r\n\r\nNo pre-processing\r\nResampling: Cross-Validated (10 fold) \r\nSummary of sample sizes: 7201, 7200, 7201, 7201, 7201, 7201, ... \r\nResampling results across tuning parameters:\r\n\r\n  mtry  Accuracy   Kappa    \r\n   2    0.8782676  0.7565151\r\n   4    0.8776418  0.7552764\r\n   6    0.8765171  0.7530258\r\n   8    0.8737676  0.7475261\r\n  10    0.8722670  0.7445177\r\n\r\nAccuracy was used to select the optimal model using the\r\n largest value.\r\nThe final value used for the model was mtry = 2.\r\n\r\n\r\n\r\nrfpred <- predict(rf, train)\r\n\r\nrf_params <- confusionMatrix(train$claim, rfpred, positive = '1')\r\n\r\n\r\nrf_accuracy <- rf_params$overall[1]\r\nrf_kappa <- rf_params$overall[2]\r\nrf_accuracy_lower <- rf_params$overall[3]\r\nrf_accuracy_upper <- rf_params$overall[4]\r\n\r\n\r\nrfprob <- predict(rf, train, type = 'prob')\r\n\r\nrf_sentivity <- rf_params$byClass[1]\r\nrf_specificity <- rf_params$byClass[2]\r\nrf_precision <- rf_params$byClass[5]\r\nrf_recall <- rf_params$byClass[6]\r\nrf_f1 <- rf_params$byClass[7]\r\nrf_prevalence <- rf_params$byClass[8]\r\n\r\n\r\n\r\nGBM {Gradient Boosting Model}\r\n\r\n\r\nset.seed(125)\r\n\r\nsystem.time(\r\n  boost <- train(\r\n    claim ~.,\r\n    data = train,\r\n    method = 'gbm',\r\n    verbose = FALSE,\r\n    tuneGrid = expand.grid(\r\n      n.trees = c(50, 100, 200),\r\n      interaction.depth = c(5, 9, 13),\r\n      shrinkage = 0.1,\r\n      n.minobsinnode = 50\r\n    )\r\n  )\r\n)\r\n\r\n\r\n   user  system elapsed \r\n 195.77    0.72  223.16 \r\n\r\nboost\r\n\r\n\r\nStochastic Gradient Boosting \r\n\r\n8001 samples\r\n  10 predictor\r\n   2 classes: '0', '1' \r\n\r\nNo pre-processing\r\nResampling: Bootstrapped (25 reps) \r\nSummary of sample sizes: 8001, 8001, 8001, 8001, 8001, 8001, ... \r\nResampling results across tuning parameters:\r\n\r\n  interaction.depth  n.trees  Accuracy   Kappa    \r\n   5                  50      0.8530858  0.7061292\r\n   5                 100      0.8645368  0.7290376\r\n   5                 200      0.8690075  0.7379822\r\n   9                  50      0.8639361  0.7278222\r\n   9                 100      0.8693879  0.7387322\r\n   9                 200      0.8699872  0.7399403\r\n  13                  50      0.8670066  0.7339638\r\n  13                 100      0.8704400  0.7408458\r\n  13                 200      0.8693575  0.7386824\r\n\r\nTuning parameter 'shrinkage' was held constant at a value of\r\n 0.1\r\nTuning parameter 'n.minobsinnode' was held constant at a\r\n value of 50\r\nAccuracy was used to select the optimal model using the\r\n largest value.\r\nThe final values used for the model were n.trees =\r\n 100, interaction.depth = 13, shrinkage = 0.1 and n.minobsinnode = 50.\r\n\r\n\r\n\r\nboostpred <- predict(boost, train)\r\n\r\nboost_params <- confusionMatrix(train$claim, boostpred, positive = '1')\r\n\r\n\r\nboost_accuracy <- boost_params$overall[1]\r\nboost_kappa <- boost_params$overall[2]\r\nboost_accuracy_lower <- boost_params$overall[3]\r\nboost_accuracy_upper <- boost_params$overall[4]\r\n\r\n\r\nboostprob <- predict(boost, train, type = 'prob')\r\n\r\n\r\nboost_sentivity <- boost_params$byClass[1]\r\nboost_specificity <- boost_params$byClass[2]\r\nboost_precision <- boost_params$byClass[5]\r\nboost_recall <- boost_params$byClass[6]\r\nboost_f1 <- boost_params$byClass[7]\r\nboost_prevalence <- boost_params$byClass[8]\r\n\r\n\r\n\r\nMLP {Multi-Perceptron}\r\n\r\n\r\nset.seed(456)\r\nsystem.time(\r\n  nnet <- train(\r\n    claim ~ .,\r\n    data = train,\r\n    method = 'mlp',\r\n    verbose = F,\r\n    tuneGrid = expand.grid(size = c(5, 7,9,10)),\r\n    trControl = tc\r\n  )\r\n)\r\n\r\n\r\n   user  system elapsed \r\n  72.65    0.16   82.31 \r\n\r\nnnet\r\n\r\n\r\nMulti-Layer Perceptron \r\n\r\n8001 samples\r\n  10 predictor\r\n   2 classes: '0', '1' \r\n\r\nNo pre-processing\r\nResampling: Cross-Validated (10 fold) \r\nSummary of sample sizes: 7201, 7201, 7200, 7201, 7200, 7201, ... \r\nResampling results across tuning parameters:\r\n\r\n  size  Accuracy   Kappa    \r\n   5    0.8730157  0.7460240\r\n   7    0.8766387  0.7532842\r\n   9    0.8816401  0.7632832\r\n  10    0.8821382  0.7642772\r\n\r\nAccuracy was used to select the optimal model using the\r\n largest value.\r\nThe final value used for the model was size = 10.\r\n\r\n\r\n\r\nnnetpred <- predict(nnet, train)\r\n\r\nnnet_params <- confusionMatrix(train$claim, nnetpred, positive = '1')\r\n\r\n\r\nnnet_accuracy <- nnet_params$overall[1]\r\nnnet_kappa <- nnet_params$overall[2]\r\nnnet_accuracy_lower <- nnet_params$overall[3]\r\nnnet_accuracy_upper <- nnet_params$overall[4]\r\n\r\n\r\nnnetprob <- predict(nnet, train, type = 'prob')\r\n\r\nnnet_sentivity <- nnet_params$byClass[1]\r\nnnet_specificity <- nnet_params$byClass[2]\r\nnnet_precision <- nnet_params$byClass[5]\r\nnnet_recall <- nnet_params$byClass[6]\r\nnnet_f1 <- nnet_params$byClass[7]\r\nnnet_prevalence <- nnet_params$byClass[8]\r\n\r\n\r\n\r\nKNN {k-Nearest Neighbours}\r\n\r\n\r\nset.seed(457)\r\n\r\nsystem.time(\r\n  knn <- train(\r\n    claim ~ .,\r\n    data = train,\r\n    method = 'knn',\r\n    trControl = tc,\r\n    tuneGrid = expand.grid(\r\n      k = c(5, 9, 11, 13, 15, 17)\r\n    )\r\n  )\r\n)\r\n\r\n\r\n   user  system elapsed \r\n   5.31    0.01    6.09 \r\n\r\nknn\r\n\r\n\r\nk-Nearest Neighbors \r\n\r\n8001 samples\r\n  10 predictor\r\n   2 classes: '0', '1' \r\n\r\nNo pre-processing\r\nResampling: Cross-Validated (10 fold) \r\nSummary of sample sizes: 7201, 7201, 7200, 7201, 7200, 7202, ... \r\nResampling results across tuning parameters:\r\n\r\n  k   Accuracy   Kappa    \r\n   5  0.8801429  0.7602601\r\n   9  0.8860168  0.7720218\r\n  11  0.8862665  0.7725258\r\n  13  0.8866412  0.7732795\r\n  15  0.8862664  0.7725269\r\n  17  0.8863914  0.7727752\r\n\r\nAccuracy was used to select the optimal model using the\r\n largest value.\r\nThe final value used for the model was k = 13.\r\n\r\n\r\n\r\nknnpred <- predict(knn, train)\r\n\r\nknn_params <- confusionMatrix(train$claim, knnpred, positive = '1')\r\n\r\n\r\nknn_accuracy <- knn_params$overall[1]\r\nknn_kappa <- knn_params$overall[2]\r\nknn_accuracy_lower <- knn_params$overall[3]\r\nknn_accuracy_upper <- knn_params$overall[4]\r\n\r\n\r\nknnprob <- predict(knn, train, type = 'prob')\r\n\r\n\r\nknn_sentivity <- knn_params$byClass[1]\r\nknn_specificity <- knn_params$byClass[2]\r\nknn_precision <- knn_params$byClass[5]\r\nknn_recall <- knn_params$byClass[6]\r\nknn_f1 <- knn_params$byClass[7]\r\nknn_prevalence <- knn_params$byClass[8]\r\n\r\n\r\n\r\nTABLE\r\n\r\n\r\ndf <- data.frame(\r\n  model = c('lda', 'qda', 'logistic', 'cart', 'randomforest', \r\n            'boosting', 'mlp', 'knn'),\r\n  accuracy = c(lda_accuracy, qda_accuracy, logit_accuracy, tree_accuracy,\r\n               rf_accuracy, boost_accuracy, nnet_accuracy, knn_accuracy),\r\n  acc_lower = c(lda_accuracy_lower, qda_accuracy_lower,\r\n                logit_accuracy_lower,tree_accuracy_lower,rf_accuracy_lower,\r\n                boost_accuracy_lower,\r\n                nnet_accuracy_lower, knn_accuracy_lower),\r\n  acc_upper = c(lda_accuracy_upper,qda_accuracy_upper,logit_accuracy_upper,\r\n                tree_accuracy_upper,rf_accuracy_upper,boost_accuracy_upper,\r\n                nnet_accuracy_upper, knn_accuracy_upper),\r\n  kappa = c(lda_kappa, qda_kappa, logit_kappa, tree_kappa, rf_kappa,\r\n            boost_kappa, nnet_kappa, knn_kappa),\r\n  senstivity = c(lda_sentivity, qda_sentivity, logit_sentivity, \r\n                 tree_sentivity, rf_sentivity, boost_sentivity, \r\n                 nnet_sentivity, knn_sentivity),\r\n  specificity = c(lda_specificity, qda_specificity, logit_specificity, \r\n                  tree_specificity, rf_specificity, boost_specificity,     \r\n                  nnet_specificity, knn_specificity),\r\n  precision = c(lda_precision, qda_precision, logit_precision,  \r\n                tree_precision, rf_precision, boost_precision,  \r\n                nnet_precision, knn_precision),\r\n  recall = c(lda_recall, qda_recall, logit_recall, tree_recall, rf_recall,\r\n             boost_recall, nnet_recall, knn_recall),\r\n  f1 = c(lda_f1, qda_f1, logit_f1, tree_f1, rf_f1, boost_f1, nnet_f1, \r\n         knn_f1),\r\n  prevalence = c(lda_prevalence, qda_prevalence, logit_prevalence, \r\n                 tree_prevalence, rf_prevalence, boost_prevalence, \r\n                 nnet_prevalence, knn_prevalence)\r\n)\r\ndf[, -1] <- round(df[, -1], 3)\r\n\r\ndf$model <- toupper(df$model)\r\nnames(df) <- toupper(names(df))\r\n\r\n\r\n\r\n\r\n\r\nd <- data.frame(\r\nx <- c(0,1),\r\ny <- c(0,1)\r\n)\r\n\r\nggplot(d, aes(x, y))+\r\n  \r\n  geom_rect(aes(xmin = 0, xmax = 0.1, ymin = 0, ymax = 0.5), color = 'sienna2', fill = 'tan4')+\r\n  geom_rect(aes(xmin = 0.1, xmax = 0.6, ymin = 0, ymax = 0.5), color = 'sienna2', fill = 'tan4')+\r\n  geom_rect(aes(xmin = 0.1, xmax = 0.6, ymin = 0.5, ymax = 0.9), color = 'sienna2', fill = 'tan4')+\r\n  geom_rect(aes(xmin = 0, xmax = 0.1, ymin = 0.5, ymax = 0.9), color = 'sienna2', fill = 'tan4')+\r\n  \r\n  \r\n  geom_rect(aes(xmin = 0.1, xmax = 0.6, ymin = 0.9, ymax = 1), color = 'sienna2', fill = 'tan4')+\r\n  geom_rect(aes(xmin = 0.6, xmax = 1, ymin = 0.9, ymax = 1), color = 'sienna2', fill = 'tan4')+\r\n  geom_rect(aes(xmin = 0.6, xmax = 1, ymin = 0, ymax = 0.5), color = 'sienna2', fill = 'tan4')+\r\n  geom_rect(aes(xmin = 0.6, xmax = 1, ymin = 0.5, ymax = 0.9), color = 'sienna2', fill = 'tan4')+\r\n  \r\n  labs(x = \"TRUE VALUES\", y = \"PREDICTED VALUE\")+\r\n  \r\n  geom_text(aes(x = 0.05, y = 0.25), label = \"TRUE\", size = 3, color = 'seashell')+\r\n  geom_text(aes(x = 0.05, y = 0.75), label = \"FALSE\", size = 3, color = 'seashell')+\r\n  geom_text(aes(x = 0.35, y = 0.25), label = \"FALSE POSITIVE\", size = 6, color = 'seashell')+\r\n  geom_text(aes(x = 0.35, y = 0.7), label = \"TRUE NEGATIVE\", size = 6, color = 'seashell')+\r\n  geom_text(aes(x = 0.35, y = 0.95), label = \"FALSE\", size = 3, color = 'seashell')+\r\n  geom_text(aes(x = 0.80, y = 0.95), label = \"TRUE\", size = 3, color = 'seashell')+\r\n  geom_text(aes(x = 0.80, y = 0.25), label = \"TRUE POSITIVE\", size = 6, color = 'seashell')+\r\n  geom_text(aes(x = 0.80, y = 0.7), label = \"FALSE NEGATIVE\", size = 6, color = 'seashell')+\r\n  \r\n  \r\n  theme(text = element_text(colour = \"royalblue1\", size = 15, family = \"serif\"),\r\n        axis.ticks = element_blank(),\r\n        axis.text = element_blank(), \r\n        panel.grid = element_blank(), \r\n        panel.background = element_blank())\r\n\r\n\r\n\r\n\r\n\r\n\r\ndf %>% select(\"MODEL\", \"ACCURACY\",  \"KAPPA\", \"ACC_LOWER\", \"ACC_UPPER\") %>% \r\n  gt()\r\n\r\n\r\n\r\nhtml {\r\n  font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, 'Helvetica Neue', 'Fira Sans', 'Droid Sans', Arial, sans-serif;\r\n}\r\n\r\n#ogwkzkdhkb .gt_table {\r\n  display: table;\r\n  border-collapse: collapse;\r\n  margin-left: auto;\r\n  margin-right: auto;\r\n  color: #333333;\r\n  font-size: 16px;\r\n  font-weight: normal;\r\n  font-style: normal;\r\n  background-color: #FFFFFF;\r\n  width: auto;\r\n  border-top-style: solid;\r\n  border-top-width: 2px;\r\n  border-top-color: #A8A8A8;\r\n  border-right-style: none;\r\n  border-right-width: 2px;\r\n  border-right-color: #D3D3D3;\r\n  border-bottom-style: solid;\r\n  border-bottom-width: 2px;\r\n  border-bottom-color: #A8A8A8;\r\n  border-left-style: none;\r\n  border-left-width: 2px;\r\n  border-left-color: #D3D3D3;\r\n}\r\n\r\n#ogwkzkdhkb .gt_heading {\r\n  background-color: #FFFFFF;\r\n  text-align: center;\r\n  border-bottom-color: #FFFFFF;\r\n  border-left-style: none;\r\n  border-left-width: 1px;\r\n  border-left-color: #D3D3D3;\r\n  border-right-style: none;\r\n  border-right-width: 1px;\r\n  border-right-color: #D3D3D3;\r\n}\r\n\r\n#ogwkzkdhkb .gt_title {\r\n  color: #333333;\r\n  font-size: 125%;\r\n  font-weight: initial;\r\n  padding-top: 4px;\r\n  padding-bottom: 4px;\r\n  border-bottom-color: #FFFFFF;\r\n  border-bottom-width: 0;\r\n}\r\n\r\n#ogwkzkdhkb .gt_subtitle {\r\n  color: #333333;\r\n  font-size: 85%;\r\n  font-weight: initial;\r\n  padding-top: 0;\r\n  padding-bottom: 6px;\r\n  border-top-color: #FFFFFF;\r\n  border-top-width: 0;\r\n}\r\n\r\n#ogwkzkdhkb .gt_bottom_border {\r\n  border-bottom-style: solid;\r\n  border-bottom-width: 2px;\r\n  border-bottom-color: #D3D3D3;\r\n}\r\n\r\n#ogwkzkdhkb .gt_col_headings {\r\n  border-top-style: solid;\r\n  border-top-width: 2px;\r\n  border-top-color: #D3D3D3;\r\n  border-bottom-style: solid;\r\n  border-bottom-width: 2px;\r\n  border-bottom-color: #D3D3D3;\r\n  border-left-style: none;\r\n  border-left-width: 1px;\r\n  border-left-color: #D3D3D3;\r\n  border-right-style: none;\r\n  border-right-width: 1px;\r\n  border-right-color: #D3D3D3;\r\n}\r\n\r\n#ogwkzkdhkb .gt_col_heading {\r\n  color: #333333;\r\n  background-color: #FFFFFF;\r\n  font-size: 100%;\r\n  font-weight: normal;\r\n  text-transform: inherit;\r\n  border-left-style: none;\r\n  border-left-width: 1px;\r\n  border-left-color: #D3D3D3;\r\n  border-right-style: none;\r\n  border-right-width: 1px;\r\n  border-right-color: #D3D3D3;\r\n  vertical-align: bottom;\r\n  padding-top: 5px;\r\n  padding-bottom: 6px;\r\n  padding-left: 5px;\r\n  padding-right: 5px;\r\n  overflow-x: hidden;\r\n}\r\n\r\n#ogwkzkdhkb .gt_column_spanner_outer {\r\n  color: #333333;\r\n  background-color: #FFFFFF;\r\n  font-size: 100%;\r\n  font-weight: normal;\r\n  text-transform: inherit;\r\n  padding-top: 0;\r\n  padding-bottom: 0;\r\n  padding-left: 4px;\r\n  padding-right: 4px;\r\n}\r\n\r\n#ogwkzkdhkb .gt_column_spanner_outer:first-child {\r\n  padding-left: 0;\r\n}\r\n\r\n#ogwkzkdhkb .gt_column_spanner_outer:last-child {\r\n  padding-right: 0;\r\n}\r\n\r\n#ogwkzkdhkb .gt_column_spanner {\r\n  border-bottom-style: solid;\r\n  border-bottom-width: 2px;\r\n  border-bottom-color: #D3D3D3;\r\n  vertical-align: bottom;\r\n  padding-top: 5px;\r\n  padding-bottom: 5px;\r\n  overflow-x: hidden;\r\n  display: inline-block;\r\n  width: 100%;\r\n}\r\n\r\n#ogwkzkdhkb .gt_group_heading {\r\n  padding: 8px;\r\n  color: #333333;\r\n  background-color: #FFFFFF;\r\n  font-size: 100%;\r\n  font-weight: initial;\r\n  text-transform: inherit;\r\n  border-top-style: solid;\r\n  border-top-width: 2px;\r\n  border-top-color: #D3D3D3;\r\n  border-bottom-style: solid;\r\n  border-bottom-width: 2px;\r\n  border-bottom-color: #D3D3D3;\r\n  border-left-style: none;\r\n  border-left-width: 1px;\r\n  border-left-color: #D3D3D3;\r\n  border-right-style: none;\r\n  border-right-width: 1px;\r\n  border-right-color: #D3D3D3;\r\n  vertical-align: middle;\r\n}\r\n\r\n#ogwkzkdhkb .gt_empty_group_heading {\r\n  padding: 0.5px;\r\n  color: #333333;\r\n  background-color: #FFFFFF;\r\n  font-size: 100%;\r\n  font-weight: initial;\r\n  border-top-style: solid;\r\n  border-top-width: 2px;\r\n  border-top-color: #D3D3D3;\r\n  border-bottom-style: solid;\r\n  border-bottom-width: 2px;\r\n  border-bottom-color: #D3D3D3;\r\n  vertical-align: middle;\r\n}\r\n\r\n#ogwkzkdhkb .gt_from_md > :first-child {\r\n  margin-top: 0;\r\n}\r\n\r\n#ogwkzkdhkb .gt_from_md > :last-child {\r\n  margin-bottom: 0;\r\n}\r\n\r\n#ogwkzkdhkb .gt_row {\r\n  padding-top: 8px;\r\n  padding-bottom: 8px;\r\n  padding-left: 5px;\r\n  padding-right: 5px;\r\n  margin: 10px;\r\n  border-top-style: solid;\r\n  border-top-width: 1px;\r\n  border-top-color: #D3D3D3;\r\n  border-left-style: none;\r\n  border-left-width: 1px;\r\n  border-left-color: #D3D3D3;\r\n  border-right-style: none;\r\n  border-right-width: 1px;\r\n  border-right-color: #D3D3D3;\r\n  vertical-align: middle;\r\n  overflow-x: hidden;\r\n}\r\n\r\n#ogwkzkdhkb .gt_stub {\r\n  color: #333333;\r\n  background-color: #FFFFFF;\r\n  font-size: 100%;\r\n  font-weight: initial;\r\n  text-transform: inherit;\r\n  border-right-style: solid;\r\n  border-right-width: 2px;\r\n  border-right-color: #D3D3D3;\r\n  padding-left: 12px;\r\n}\r\n\r\n#ogwkzkdhkb .gt_summary_row {\r\n  color: #333333;\r\n  background-color: #FFFFFF;\r\n  text-transform: inherit;\r\n  padding-top: 8px;\r\n  padding-bottom: 8px;\r\n  padding-left: 5px;\r\n  padding-right: 5px;\r\n}\r\n\r\n#ogwkzkdhkb .gt_first_summary_row {\r\n  padding-top: 8px;\r\n  padding-bottom: 8px;\r\n  padding-left: 5px;\r\n  padding-right: 5px;\r\n  border-top-style: solid;\r\n  border-top-width: 2px;\r\n  border-top-color: #D3D3D3;\r\n}\r\n\r\n#ogwkzkdhkb .gt_grand_summary_row {\r\n  color: #333333;\r\n  background-color: #FFFFFF;\r\n  text-transform: inherit;\r\n  padding-top: 8px;\r\n  padding-bottom: 8px;\r\n  padding-left: 5px;\r\n  padding-right: 5px;\r\n}\r\n\r\n#ogwkzkdhkb .gt_first_grand_summary_row {\r\n  padding-top: 8px;\r\n  padding-bottom: 8px;\r\n  padding-left: 5px;\r\n  padding-right: 5px;\r\n  border-top-style: double;\r\n  border-top-width: 6px;\r\n  border-top-color: #D3D3D3;\r\n}\r\n\r\n#ogwkzkdhkb .gt_striped {\r\n  background-color: rgba(128, 128, 128, 0.05);\r\n}\r\n\r\n#ogwkzkdhkb .gt_table_body {\r\n  border-top-style: solid;\r\n  border-top-width: 2px;\r\n  border-top-color: #D3D3D3;\r\n  border-bottom-style: solid;\r\n  border-bottom-width: 2px;\r\n  border-bottom-color: #D3D3D3;\r\n}\r\n\r\n#ogwkzkdhkb .gt_footnotes {\r\n  color: #333333;\r\n  background-color: #FFFFFF;\r\n  border-bottom-style: none;\r\n  border-bottom-width: 2px;\r\n  border-bottom-color: #D3D3D3;\r\n  border-left-style: none;\r\n  border-left-width: 2px;\r\n  border-left-color: #D3D3D3;\r\n  border-right-style: none;\r\n  border-right-width: 2px;\r\n  border-right-color: #D3D3D3;\r\n}\r\n\r\n#ogwkzkdhkb .gt_footnote {\r\n  margin: 0px;\r\n  font-size: 90%;\r\n  padding: 4px;\r\n}\r\n\r\n#ogwkzkdhkb .gt_sourcenotes {\r\n  color: #333333;\r\n  background-color: #FFFFFF;\r\n  border-bottom-style: none;\r\n  border-bottom-width: 2px;\r\n  border-bottom-color: #D3D3D3;\r\n  border-left-style: none;\r\n  border-left-width: 2px;\r\n  border-left-color: #D3D3D3;\r\n  border-right-style: none;\r\n  border-right-width: 2px;\r\n  border-right-color: #D3D3D3;\r\n}\r\n\r\n#ogwkzkdhkb .gt_sourcenote {\r\n  font-size: 90%;\r\n  padding: 4px;\r\n}\r\n\r\n#ogwkzkdhkb .gt_left {\r\n  text-align: left;\r\n}\r\n\r\n#ogwkzkdhkb .gt_center {\r\n  text-align: center;\r\n}\r\n\r\n#ogwkzkdhkb .gt_right {\r\n  text-align: right;\r\n  font-variant-numeric: tabular-nums;\r\n}\r\n\r\n#ogwkzkdhkb .gt_font_normal {\r\n  font-weight: normal;\r\n}\r\n\r\n#ogwkzkdhkb .gt_font_bold {\r\n  font-weight: bold;\r\n}\r\n\r\n#ogwkzkdhkb .gt_font_italic {\r\n  font-style: italic;\r\n}\r\n\r\n#ogwkzkdhkb .gt_super {\r\n  font-size: 65%;\r\n}\r\n\r\n#ogwkzkdhkb .gt_footnote_marks {\r\n  font-style: italic;\r\n  font-weight: normal;\r\n  font-size: 65%;\r\n}\r\nMODEL\r\n      ACCURACY\r\n      KAPPA\r\n      ACC_LOWER\r\n      ACC_UPPER\r\n    LDA\r\n0.818\r\n0.636\r\n0.810\r\n0.827QDA\r\n0.876\r\n0.752\r\n0.869\r\n0.883LOGISTIC\r\n0.821\r\n0.641\r\n0.812\r\n0.829CART\r\n0.766\r\n0.531\r\n0.756\r\n0.775RANDOMFOREST\r\n1.000\r\n1.000\r\n1.000\r\n1.000BOOSTING\r\n0.889\r\n0.777\r\n0.881\r\n0.895MLP\r\n0.890\r\n0.780\r\n0.883\r\n0.897KNN\r\n0.888\r\n0.777\r\n0.881\r\n0.895\r\n\r\ndf %>% select(\"MODEL\", \"SENSTIVITY\", \"SPECIFICITY\", \"RECALL\", \"F1\", \"PREVALENCE\") %>% \r\n  gt()\r\n\r\n\r\n\r\nhtml {\r\n  font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, 'Helvetica Neue', 'Fira Sans', 'Droid Sans', Arial, sans-serif;\r\n}\r\n\r\n#agsrmybsbv .gt_table {\r\n  display: table;\r\n  border-collapse: collapse;\r\n  margin-left: auto;\r\n  margin-right: auto;\r\n  color: #333333;\r\n  font-size: 16px;\r\n  font-weight: normal;\r\n  font-style: normal;\r\n  background-color: #FFFFFF;\r\n  width: auto;\r\n  border-top-style: solid;\r\n  border-top-width: 2px;\r\n  border-top-color: #A8A8A8;\r\n  border-right-style: none;\r\n  border-right-width: 2px;\r\n  border-right-color: #D3D3D3;\r\n  border-bottom-style: solid;\r\n  border-bottom-width: 2px;\r\n  border-bottom-color: #A8A8A8;\r\n  border-left-style: none;\r\n  border-left-width: 2px;\r\n  border-left-color: #D3D3D3;\r\n}\r\n\r\n#agsrmybsbv .gt_heading {\r\n  background-color: #FFFFFF;\r\n  text-align: center;\r\n  border-bottom-color: #FFFFFF;\r\n  border-left-style: none;\r\n  border-left-width: 1px;\r\n  border-left-color: #D3D3D3;\r\n  border-right-style: none;\r\n  border-right-width: 1px;\r\n  border-right-color: #D3D3D3;\r\n}\r\n\r\n#agsrmybsbv .gt_title {\r\n  color: #333333;\r\n  font-size: 125%;\r\n  font-weight: initial;\r\n  padding-top: 4px;\r\n  padding-bottom: 4px;\r\n  border-bottom-color: #FFFFFF;\r\n  border-bottom-width: 0;\r\n}\r\n\r\n#agsrmybsbv .gt_subtitle {\r\n  color: #333333;\r\n  font-size: 85%;\r\n  font-weight: initial;\r\n  padding-top: 0;\r\n  padding-bottom: 6px;\r\n  border-top-color: #FFFFFF;\r\n  border-top-width: 0;\r\n}\r\n\r\n#agsrmybsbv .gt_bottom_border {\r\n  border-bottom-style: solid;\r\n  border-bottom-width: 2px;\r\n  border-bottom-color: #D3D3D3;\r\n}\r\n\r\n#agsrmybsbv .gt_col_headings {\r\n  border-top-style: solid;\r\n  border-top-width: 2px;\r\n  border-top-color: #D3D3D3;\r\n  border-bottom-style: solid;\r\n  border-bottom-width: 2px;\r\n  border-bottom-color: #D3D3D3;\r\n  border-left-style: none;\r\n  border-left-width: 1px;\r\n  border-left-color: #D3D3D3;\r\n  border-right-style: none;\r\n  border-right-width: 1px;\r\n  border-right-color: #D3D3D3;\r\n}\r\n\r\n#agsrmybsbv .gt_col_heading {\r\n  color: #333333;\r\n  background-color: #FFFFFF;\r\n  font-size: 100%;\r\n  font-weight: normal;\r\n  text-transform: inherit;\r\n  border-left-style: none;\r\n  border-left-width: 1px;\r\n  border-left-color: #D3D3D3;\r\n  border-right-style: none;\r\n  border-right-width: 1px;\r\n  border-right-color: #D3D3D3;\r\n  vertical-align: bottom;\r\n  padding-top: 5px;\r\n  padding-bottom: 6px;\r\n  padding-left: 5px;\r\n  padding-right: 5px;\r\n  overflow-x: hidden;\r\n}\r\n\r\n#agsrmybsbv .gt_column_spanner_outer {\r\n  color: #333333;\r\n  background-color: #FFFFFF;\r\n  font-size: 100%;\r\n  font-weight: normal;\r\n  text-transform: inherit;\r\n  padding-top: 0;\r\n  padding-bottom: 0;\r\n  padding-left: 4px;\r\n  padding-right: 4px;\r\n}\r\n\r\n#agsrmybsbv .gt_column_spanner_outer:first-child {\r\n  padding-left: 0;\r\n}\r\n\r\n#agsrmybsbv .gt_column_spanner_outer:last-child {\r\n  padding-right: 0;\r\n}\r\n\r\n#agsrmybsbv .gt_column_spanner {\r\n  border-bottom-style: solid;\r\n  border-bottom-width: 2px;\r\n  border-bottom-color: #D3D3D3;\r\n  vertical-align: bottom;\r\n  padding-top: 5px;\r\n  padding-bottom: 5px;\r\n  overflow-x: hidden;\r\n  display: inline-block;\r\n  width: 100%;\r\n}\r\n\r\n#agsrmybsbv .gt_group_heading {\r\n  padding: 8px;\r\n  color: #333333;\r\n  background-color: #FFFFFF;\r\n  font-size: 100%;\r\n  font-weight: initial;\r\n  text-transform: inherit;\r\n  border-top-style: solid;\r\n  border-top-width: 2px;\r\n  border-top-color: #D3D3D3;\r\n  border-bottom-style: solid;\r\n  border-bottom-width: 2px;\r\n  border-bottom-color: #D3D3D3;\r\n  border-left-style: none;\r\n  border-left-width: 1px;\r\n  border-left-color: #D3D3D3;\r\n  border-right-style: none;\r\n  border-right-width: 1px;\r\n  border-right-color: #D3D3D3;\r\n  vertical-align: middle;\r\n}\r\n\r\n#agsrmybsbv .gt_empty_group_heading {\r\n  padding: 0.5px;\r\n  color: #333333;\r\n  background-color: #FFFFFF;\r\n  font-size: 100%;\r\n  font-weight: initial;\r\n  border-top-style: solid;\r\n  border-top-width: 2px;\r\n  border-top-color: #D3D3D3;\r\n  border-bottom-style: solid;\r\n  border-bottom-width: 2px;\r\n  border-bottom-color: #D3D3D3;\r\n  vertical-align: middle;\r\n}\r\n\r\n#agsrmybsbv .gt_from_md > :first-child {\r\n  margin-top: 0;\r\n}\r\n\r\n#agsrmybsbv .gt_from_md > :last-child {\r\n  margin-bottom: 0;\r\n}\r\n\r\n#agsrmybsbv .gt_row {\r\n  padding-top: 8px;\r\n  padding-bottom: 8px;\r\n  padding-left: 5px;\r\n  padding-right: 5px;\r\n  margin: 10px;\r\n  border-top-style: solid;\r\n  border-top-width: 1px;\r\n  border-top-color: #D3D3D3;\r\n  border-left-style: none;\r\n  border-left-width: 1px;\r\n  border-left-color: #D3D3D3;\r\n  border-right-style: none;\r\n  border-right-width: 1px;\r\n  border-right-color: #D3D3D3;\r\n  vertical-align: middle;\r\n  overflow-x: hidden;\r\n}\r\n\r\n#agsrmybsbv .gt_stub {\r\n  color: #333333;\r\n  background-color: #FFFFFF;\r\n  font-size: 100%;\r\n  font-weight: initial;\r\n  text-transform: inherit;\r\n  border-right-style: solid;\r\n  border-right-width: 2px;\r\n  border-right-color: #D3D3D3;\r\n  padding-left: 12px;\r\n}\r\n\r\n#agsrmybsbv .gt_summary_row {\r\n  color: #333333;\r\n  background-color: #FFFFFF;\r\n  text-transform: inherit;\r\n  padding-top: 8px;\r\n  padding-bottom: 8px;\r\n  padding-left: 5px;\r\n  padding-right: 5px;\r\n}\r\n\r\n#agsrmybsbv .gt_first_summary_row {\r\n  padding-top: 8px;\r\n  padding-bottom: 8px;\r\n  padding-left: 5px;\r\n  padding-right: 5px;\r\n  border-top-style: solid;\r\n  border-top-width: 2px;\r\n  border-top-color: #D3D3D3;\r\n}\r\n\r\n#agsrmybsbv .gt_grand_summary_row {\r\n  color: #333333;\r\n  background-color: #FFFFFF;\r\n  text-transform: inherit;\r\n  padding-top: 8px;\r\n  padding-bottom: 8px;\r\n  padding-left: 5px;\r\n  padding-right: 5px;\r\n}\r\n\r\n#agsrmybsbv .gt_first_grand_summary_row {\r\n  padding-top: 8px;\r\n  padding-bottom: 8px;\r\n  padding-left: 5px;\r\n  padding-right: 5px;\r\n  border-top-style: double;\r\n  border-top-width: 6px;\r\n  border-top-color: #D3D3D3;\r\n}\r\n\r\n#agsrmybsbv .gt_striped {\r\n  background-color: rgba(128, 128, 128, 0.05);\r\n}\r\n\r\n#agsrmybsbv .gt_table_body {\r\n  border-top-style: solid;\r\n  border-top-width: 2px;\r\n  border-top-color: #D3D3D3;\r\n  border-bottom-style: solid;\r\n  border-bottom-width: 2px;\r\n  border-bottom-color: #D3D3D3;\r\n}\r\n\r\n#agsrmybsbv .gt_footnotes {\r\n  color: #333333;\r\n  background-color: #FFFFFF;\r\n  border-bottom-style: none;\r\n  border-bottom-width: 2px;\r\n  border-bottom-color: #D3D3D3;\r\n  border-left-style: none;\r\n  border-left-width: 2px;\r\n  border-left-color: #D3D3D3;\r\n  border-right-style: none;\r\n  border-right-width: 2px;\r\n  border-right-color: #D3D3D3;\r\n}\r\n\r\n#agsrmybsbv .gt_footnote {\r\n  margin: 0px;\r\n  font-size: 90%;\r\n  padding: 4px;\r\n}\r\n\r\n#agsrmybsbv .gt_sourcenotes {\r\n  color: #333333;\r\n  background-color: #FFFFFF;\r\n  border-bottom-style: none;\r\n  border-bottom-width: 2px;\r\n  border-bottom-color: #D3D3D3;\r\n  border-left-style: none;\r\n  border-left-width: 2px;\r\n  border-left-color: #D3D3D3;\r\n  border-right-style: none;\r\n  border-right-width: 2px;\r\n  border-right-color: #D3D3D3;\r\n}\r\n\r\n#agsrmybsbv .gt_sourcenote {\r\n  font-size: 90%;\r\n  padding: 4px;\r\n}\r\n\r\n#agsrmybsbv .gt_left {\r\n  text-align: left;\r\n}\r\n\r\n#agsrmybsbv .gt_center {\r\n  text-align: center;\r\n}\r\n\r\n#agsrmybsbv .gt_right {\r\n  text-align: right;\r\n  font-variant-numeric: tabular-nums;\r\n}\r\n\r\n#agsrmybsbv .gt_font_normal {\r\n  font-weight: normal;\r\n}\r\n\r\n#agsrmybsbv .gt_font_bold {\r\n  font-weight: bold;\r\n}\r\n\r\n#agsrmybsbv .gt_font_italic {\r\n  font-style: italic;\r\n}\r\n\r\n#agsrmybsbv .gt_super {\r\n  font-size: 65%;\r\n}\r\n\r\n#agsrmybsbv .gt_footnote_marks {\r\n  font-style: italic;\r\n  font-weight: normal;\r\n  font-size: 65%;\r\n}\r\nMODEL\r\n      SENSTIVITY\r\n      SPECIFICITY\r\n      RECALL\r\n      F1\r\n      PREVALENCE\r\n    LDA\r\n0.820\r\n0.817\r\n0.820\r\n0.815\r\n0.489QDA\r\n0.873\r\n0.879\r\n0.873\r\n0.875\r\n0.497LOGISTIC\r\n0.821\r\n0.821\r\n0.821\r\n0.818\r\n0.492CART\r\n0.794\r\n0.743\r\n0.794\r\n0.750\r\n0.443RANDOMFOREST\r\n1.000\r\n1.000\r\n1.000\r\n1.000\r\n0.495BOOSTING\r\n0.884\r\n0.893\r\n0.884\r\n0.888\r\n0.499MLP\r\n0.888\r\n0.892\r\n0.888\r\n0.889\r\n0.495KNN\r\n0.885\r\n0.892\r\n0.885\r\n0.887\r\n0.498\r\n\r\nGRAPH\r\n\r\n\r\nggplot(df, aes(MODEL, ACCURACY)) +\r\n  geom_pointrange(aes(ymin = ACC_LOWER, ymax = ACC_UPPER), \r\n                  col = 'red', alpha = 0.5, size = 0.9) +\r\n  coord_flip()+\r\n  labs(y = \"\", x = \"ACCURACY\")+\r\n  theme(text = element_text(family = 'serif', size = 15),\r\n        panel.background = element_rect(fill = 'royalblue1'))\r\n\r\n\r\n\r\n\r\n\r\n\r\nggplot(df, aes(MODEL, SENSITIVITY)) +\r\n  geom_point(aes(MODEL, RECALL), size = 5, color = 'grey4' )+\r\n  coord_flip()+\r\n  labs(y = \"\")+\r\n  theme(text = element_text(family = 'serif', size = 15),\r\n        panel.background = element_rect(fill = 'royalblue1'))\r\n\r\n\r\n\r\n\r\n\r\n\r\nggplot(df, aes(MODEL, PRECISION)) +\r\n  geom_point(size = 5, color = 'royalblue4' )+\r\n  coord_flip()+\r\n  labs(y = \"\")+\r\n  theme(text = element_text(family = 'serif', size = 15),\r\n        panel.background = element_rect(fill = 'royalblue1'))\r\n\r\n\r\n\r\n\r\n\r\n\r\nldaroc <- roc(predictor = ldaprob$`1`, response = train$claim)\r\nqdaroc <- roc(predictor = qdaprob$`1`, response = train$claim)\r\nlogitroc <- roc(predictor = logitprob$`1`, response = train$claim)\r\ntreeroc <- roc(predictor = treeprob$`1`, response = train$claim)\r\nrfroc <- roc(predictor = rfprob$`1`, response = train$claim)\r\nboostroc <- roc(predictor = boostprob$`1`, response = train$claim)\r\nnnetroc <- roc(predictor = nnetprob$`1`, response = train$claim)\r\nknnroc <- roc(predictor = knnprob$`1`, response = train$claim)\r\n\r\nroc_curve <- data.frame(\r\n  senstivity = c(ldaroc$sensitivities, qdaroc$sensitivities, logitroc$sensitivities,\r\n                 treeroc$sensitivities, rfroc$sensitivities, boostroc$sensitivities,\r\n                 nnetroc$sensitivities),\r\n  specificity = c(ldaroc$specificities, qdaroc$specificities, logitroc$specificities,\r\n                  treeroc$specificities, rfroc$specificities, boostroc$specificities,\r\n                  nnetroc$specificities),\r\n  model = c(rep(\"LDA\", length(ldaroc$specificities)), \r\n            rep(\"QDA\", length(qdaroc$specificities)),\r\n            rep(\"LOGIT\", length(logitroc$specificities)),\r\n            rep(\"TREE\", length(treeroc$specificities)),\r\n            rep(\"RF\", length(rfroc$specificities)),\r\n            rep(\"GBM\", length(boostroc$specificities)), \r\n            rep(\"MLP\", length(nnetroc$specificities)))\r\n)\r\n\r\n\r\n\r\n\r\n\r\nggplot(roc_curve, aes(x = 1-specificity, y = senstivity, group = model, color = model))+\r\n  geom_line(lwd = 1.5, alpha = 0.5)+\r\n  theme(text = element_text(family = 'serif', size = 15))\r\n\r\n\r\n\r\n\r\n\r\n\r\nfinal <- predict(rf, test)\r\n\r\nconfusionMatrix(data = test$claim, final, positive = \"1\")\r\n\r\n\r\nConfusion Matrix and Statistics\r\n\r\n          Reference\r\nPrediction   0   1\r\n         0 885 125\r\n         1 115 874\r\n                                          \r\n               Accuracy : 0.8799          \r\n                 95% CI : (0.8649, 0.8939)\r\n    No Information Rate : 0.5003          \r\n    P-Value [Acc > NIR] : <2e-16          \r\n                                          \r\n                  Kappa : 0.7599          \r\n                                          \r\n Mcnemar's Test P-Value : 0.5613          \r\n                                          \r\n            Sensitivity : 0.8749          \r\n            Specificity : 0.8850          \r\n         Pos Pred Value : 0.8837          \r\n         Neg Pred Value : 0.8762          \r\n             Prevalence : 0.4997          \r\n         Detection Rate : 0.4372          \r\n   Detection Prevalence : 0.4947          \r\n      Balanced Accuracy : 0.8799          \r\n                                          \r\n       'Positive' Class : 1               \r\n                                          \r\n\r\n\r\n\r\n\r\n",
      "last_modified": "2022-02-16T13:00:59+05:30"
    },
    {
      "path": "dt.html",
      "title": "Dates",
      "author": [],
      "contents": "\r\nDates in R\r\n\r\n\r\nSys.Date()\r\n\r\n\r\n[1] \"2022-02-16\"\r\n\r\nCode\r\nValue\r\n%d\r\nDay of the month (number)\r\n%m\r\nMonth (number)\r\n%b\r\nMonth (abbr.)\r\n%B\r\nMonth (Full Name)\r\n%y\r\nYear 2-digit\r\n%Y\r\nYear 4-digit\r\n%h\r\nHour\r\n%m\r\nMinute\r\n%s\r\nSeconds\r\n\r\n\r\nweekdays(Sys.Date() - 365) \r\n\r\n\r\n[1] \"Tuesday\"\r\n\r\n\r\n\r\nmonths(Sys.Date() + 35, 3)\r\n\r\n\r\n[1] \"Mar\"\r\n\r\n\r\n\r\ndt <- c('20/02/20', '25/09/21', '12/12/19')\r\n\r\nas.Date(dt)\r\n\r\n\r\n[1] \"0020-02-20\" \"0025-09-21\" \"0012-12-19\"\r\n\r\n\r\n\r\ndt <- as.Date(dt, format = \"%d/%m/%y\")\r\n\r\ndt\r\n\r\n\r\n[1] \"2020-02-20\" \"2021-09-25\" \"2019-12-12\"\r\n\r\n\r\n\r\n#as.numeric(\r\n  dt[2] - dt[1]\r\n\r\n\r\nTime difference of 583 days\r\n\r\n#  )\r\n\r\n\r\n\r\n\r\n\r\ndt <- c('05051994', '01232020', '01012000')\r\n\r\ndt <- as.Date(dt, format = '%m%d%Y')\r\n\r\ndt\r\n\r\n\r\n[1] \"1994-05-05\" \"2020-01-23\" \"2000-01-01\"\r\n\r\n\r\n\r\nnew2 <- Sys.Date() - dt\r\n\r\ndata.frame(dt, new2)\r\n\r\n\r\n          dt       new2\r\n1 1994-05-05 10149 days\r\n2 2020-01-23   755 days\r\n3 2000-01-01  8082 days\r\n\r\n\r\n\r\ndt <- c(25856563, 26586663)\r\n\r\nclass(dt) <- c(\"POSIXt\", \"POSIXct\")\r\n\r\n\r\ndt\r\n\r\n\r\n[1] \"1970-10-27 11:52:43 IST\" \"1970-11-04 22:41:03 IST\"\r\n\r\n\r\n\r\nformat(dt, '%d %b, %Y')\r\n\r\n\r\n[1] \"27 Oct, 1970\" \"04 Nov, 1970\"\r\n\r\n\r\n\r\n\r\n",
      "last_modified": "2022-02-16T13:01:01+05:30"
    },
    {
      "path": "fun.html",
      "title": "Writing a function and Its basics",
      "author": [],
      "contents": "\r\nWriting a function in a programming language is an art of easing work while working in either production environment or working for academia. Nobody likes to do iterative work continuously.\r\nThere are number of functions: - if & else - for loop - while - function\r\nIF Else or ifelse function\r\n\r\n\r\nif(TRUE){  # Condition is true\r\n  'true:command to do'\r\n}else{     # Condition is false\r\n  'false:command to do'\r\n}\r\n\r\n\r\n[1] \"true:command to do\"\r\n\r\nIf else is very powerful and very useful not just in R programming language but in every other language as well, Solely due to its humanly nature of dealing.\r\nThe same thing, that is above here, can be done using excel style function which is ifelse(condition, true, false). first argument is for logical condition, next is what if the condition is true and lastly what if the condition is false.\r\nFor loop\r\nOne of the most used function for e.g. data processing for each column. One must learn the concepts of loop and nested loop for understanding grid operations in machine learning\r\n\r\n\r\nfor(i in 1:10){\r\n  print(\r\n    paste0('2 multiple ', i, ' is equal = ', i*2)\r\n    )\r\n}\r\n\r\n\r\n[1] \"2 multiple 1 is equal = 2\"\r\n[1] \"2 multiple 2 is equal = 4\"\r\n[1] \"2 multiple 3 is equal = 6\"\r\n[1] \"2 multiple 4 is equal = 8\"\r\n[1] \"2 multiple 5 is equal = 10\"\r\n[1] \"2 multiple 6 is equal = 12\"\r\n[1] \"2 multiple 7 is equal = 14\"\r\n[1] \"2 multiple 8 is equal = 16\"\r\n[1] \"2 multiple 9 is equal = 18\"\r\n[1] \"2 multiple 10 is equal = 20\"\r\n\r\nNote: Nested loops are powerful, interesting to work with and greatly reduces efforts.\r\n\r\n\r\nfor(i in 1:15){\r\n  if(i%%2==0){\r\n    print(\r\n      paste0(i, ' is an even number')\r\n    )\r\n  }else{\r\n    print(\r\n      paste(i, ' is an odd number')\r\n    )\r\n  }\r\n}\r\n\r\n\r\n[1] \"1  is an odd number\"\r\n[1] \"2 is an even number\"\r\n[1] \"3  is an odd number\"\r\n[1] \"4 is an even number\"\r\n[1] \"5  is an odd number\"\r\n[1] \"6 is an even number\"\r\n[1] \"7  is an odd number\"\r\n[1] \"8 is an even number\"\r\n[1] \"9  is an odd number\"\r\n[1] \"10 is an even number\"\r\n[1] \"11  is an odd number\"\r\n[1] \"12 is an even number\"\r\n[1] \"13  is an odd number\"\r\n[1] \"14 is an even number\"\r\n[1] \"15  is an odd number\"\r\n\r\nWhile Loop\r\nWhile loop is a interesting less explored function. Which can definitely be used a lot in data science projects. Argument for while is in general like: If a logical statement is True then ‘Do a specific task’ and update the ‘i’ in conditional statement.\r\nSee given example to understand it better.\r\n\r\n\r\ni <- 1\r\n\r\nwhile (i < 5) {\r\n  print(\r\n    paste0(i, \" is less than 5\")\r\n  )\r\n  i = i+1\r\n}\r\n\r\n\r\n[1] \"1 is less than 5\"\r\n[1] \"2 is less than 5\"\r\n[1] \"3 is less than 5\"\r\n[1] \"4 is less than 5\"\r\n\r\nIn the above example, i is initially initialized to 1.\r\nHere, the test_expression is i < 5 which evaluates to TRUE since 1 is less than 5. So, the body of the loop is entered and i is printed and incremented. Increasing i is important as this will eventually meet the exit condition. Failing to do so will result into an infinite loop.\r\nIn the next iteration, the value of i is 2 and the loop continues till the value reaches to 5.\r\nFunctions\r\nThe most important part of data science cum machine learning or for data intelligence professionals journey is writing your own function in order to establish self ease of doing tasks iteratively.\r\n\r\n\r\nfunction(){\r\n  print('do something')\r\n}\r\n\r\n\r\nfunction(){\r\n  print('do something')\r\n}\r\n\r\nIn the above, We have seen the basic structure for function writing. After function one should write input argument for the function and letter in dictionary brackets we can assign operation to do.\r\nTake a look for better understanding:\r\n\r\n\r\naddition <- function(n1, n2, n3){\r\n  print(n1 + n2 + n3)\r\n}\r\n\r\naddition(1,2,3)\r\n\r\n\r\n[1] 6\r\n\r\nR is a intelligent language that it understands the position of your arguments written in function. Although If one wants to command any argument first or later, can do so.And one can also write default argument as well, in case the argument has not specified value in commanding then this value will be used.\r\nLet see:\r\n\r\n\r\naddition <- function(n1, n2, n3=0){ # default argument is 0.\r\n  print(n1 + n2 + n3)\r\n}\r\n\r\n\r\naddition(n2 = 3, n1 = 1)\r\n\r\n\r\n[1] 4\r\n\r\naddition(n2 = 3, n1 = 1, n3 = 2)\r\n\r\n\r\n[1] 6\r\n\r\nNote: There are two types of objects in R: 1. One is global object, which is everything that is not written inside function. 2. Another function object, which has a place inside the function.\r\nGlobal objects can be accessed using appropriate command since it keeps memory space in your machine. Function objects can’t be accessed outside from the function.\r\n\r\n\r\nodd_even <- function(arry){\r\n  if(arry %% 2==0){\r\n    print(\r\n      paste0(arry, ' is an even number')\r\n    )\r\n  }else{\r\n    print(\r\n      paste(arry, ' is an odd number')\r\n    )\r\n  }\r\n}\r\n\r\n\r\nodd_even(46)\r\n\r\n\r\n[1] \"46 is an even number\"\r\n\r\nfor(n in c(11,110,111,11110)) odd_even(n)\r\n\r\n\r\n[1] \"11  is an odd number\"\r\n[1] \"110 is an even number\"\r\n[1] \"111  is an odd number\"\r\n[1] \"11110 is an even number\"\r\n\r\n\r\n\r\n\r\n",
      "last_modified": "2022-02-16T13:01:03+05:30"
    },
    {
      "path": "ggplt.html",
      "title": "ggplot",
      "author": [],
      "contents": "\r\n\r\n\r\n## install.ggplot2 or install.tidyverse\r\n\r\nlibrary(ggplot2)\r\n\r\n\r\n\r\nbasic\r\n\r\n\r\nset.seed(123)\r\n\r\ndf <- data.frame(\r\n  a = 1:100,\r\n  b = sample(letters[1:10], 100, replace = T),\r\n  c = c(rep('A',50), rep('B', 50)),\r\n  d = sample(100:150, 100, TRUE)\r\n)\r\n\r\nggplot(df, aes(b, d))+\r\n  geom_point()\r\n\r\n\r\n\r\n\r\n\r\n\r\nggplot(df, aes(b, d, color = b))+\r\n  geom_point(show.legend = FALSE, size = 5, alpha = 0.3) \r\n\r\n\r\n\r\n\r\n\r\n\r\nggplot(df, aes(b, d, shape = c, color = c))+\r\n  geom_point(size = 3)\r\n\r\n\r\n\r\n\r\n\r\n\r\nggplot(df, aes(a, b, fill = b)) +\r\n  geom_col(show.legend = FALSE) \r\n\r\n\r\n\r\n\r\n\r\n\r\np1 <- ggplot(df, aes(b, d))+\r\n  geom_boxplot(outlier.colour = 'red')\r\n\r\np2 <- ggplot(df, aes(b, d))+\r\n  geom_violin()\r\n\r\np3 <- ggplot(df, aes(b, d))+\r\n  geom_boxplot(notch = TRUE, outlier.colour = 'red')\r\n\r\n\r\ngridExtra::grid.arrange(p1, p2, p3)\r\n\r\n\r\n\r\n\r\n\r\n\r\nggplot(df, aes(a, d))+\r\n  geom_point()\r\n\r\n\r\n\r\nggplot(df, aes(a, d, color = b))+\r\n  geom_point()+\r\n  geom_segment(xend = df$a, yend = 0, lineend = 'butt')\r\n\r\n\r\n\r\n\r\n\r\n\r\nggplot(df, aes(a, d, color = b))+\r\n  geom_rect(xmin = 70, xmax = 85, ymin = 90, ymax = 130,\r\n            alpha = .03, color = 'yellow', fill = 'lightblue')+\r\n  geom_point()+\r\n  geom_segment(xend = df$a, yend = 0, lineend = 'butt')\r\n\r\n\r\n\r\n\r\n\r\n\r\nggplot(df, aes(a, d, color = c))+\r\n  geom_point()+\r\n  geom_smooth(method = 'lm', se = FALSE)\r\n\r\n\r\n\r\n\r\n\r\n\r\nggplot(df, aes(b))+\r\n  geom_bar()+\r\n  geom_point(data = df, mapping = aes(b, d, color = c))\r\n\r\n\r\n\r\n\r\n\r\n\r\nggplot(df, aes(b))+\r\n  geom_bar(aes(fill = b))+\r\n  coord_polar(theta = 'x')\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n",
      "last_modified": "2022-02-16T13:01:12+05:30"
    },
    {
      "path": "idplyr.html",
      "title": "dplyr",
      "author": [],
      "contents": "\r\nMore Compatibility with production means more ease with codes\r\n\r\n\r\n# install.packages('dplyr') or install.packages('tidyverse')\r\n\r\nlibrary(dplyr)\r\n\r\n\r\n\r\n\r\n\r\nset.seed(123)\r\n\r\ndf <- data.frame(\r\n  a = 1:100,\r\n  b = sample(letters[1:10], 100, replace = T),\r\n  c = c(rep('A',50), rep('B', 50)),\r\n  d = sample(100:150, 100, TRUE)\r\n)\r\n\r\nhead(df, 10)\r\n\r\n\r\n    a b c   d\r\n1   1 c A 137\r\n2   2 c A 145\r\n3   3 j A 131\r\n4   4 b A 106\r\n5   5 f A 126\r\n6   6 e A 141\r\n7   7 d A 104\r\n8   8 f A 105\r\n9   9 i A 115\r\n10 10 j A 123\r\n\r\nselect\r\n\r\n\r\nselect(df, a, d) %>% \r\n  head()\r\n\r\n\r\n  a   d\r\n1 1 137\r\n2 2 145\r\n3 3 131\r\n4 4 106\r\n5 5 126\r\n6 6 141\r\n\r\nselect(df, d, b) %>%  \r\n  head()\r\n\r\n\r\n    d b\r\n1 137 c\r\n2 145 c\r\n3 131 j\r\n4 106 b\r\n5 126 f\r\n6 141 e\r\n\r\n#------or------------------------ \r\n\r\ndf %>% \r\n  select(b, d) %>% # or select(a, b)\r\n  glimpse()\r\n\r\n\r\nRows: 100\r\nColumns: 2\r\n$ b <chr> \"c\", \"c\", \"j\", \"b\", \"f\", \"e\", \"d\", \"f\", \"i\", \"j\", \"e\", \"c\"~\r\n$ d <int> 137, 145, 131, 106, 126, 141, 104, 105, 115, 123, 131, 120~\r\n\r\n\r\n\r\ndf %>% \r\n  select(b, c, d) %>% \r\n  group_by(c, b) %>% \r\n  summarise(\r\n    'min' = min(d),\r\n    'avg' = mean(d),\r\n    'max' = max(d), \r\n    'sd' = sd(d)\r\n  )\r\n\r\n\r\n# A tibble: 20 x 6\r\n# Groups:   c [2]\r\n   c     b       min   avg   max    sd\r\n   <chr> <chr> <int> <dbl> <int> <dbl>\r\n 1 A     a       128  138.   147 13.4 \r\n 2 A     b       102  118.   147 24.9 \r\n 3 A     c       106  131.   145 17.1 \r\n 4 A     d       104  116.   133 15.3 \r\n 5 A     e       115  129.   148 12.4 \r\n 6 A     f       105  116.   126  9.69\r\n 7 A     g       112  128.   138 10.9 \r\n 8 A     h       118  128.   139 14.8 \r\n 9 A     i       100  122.   143 17.2 \r\n10 A     j       119  130.   146  9.73\r\n11 B     a       105  123.   142 15.3 \r\n12 B     b       107  128.   150 22.1 \r\n13 B     c       106  122.   144 13.2 \r\n14 B     d       115  127.   143 14.3 \r\n15 B     e       122  126    131  4.58\r\n16 B     f       106  120.   144 13.6 \r\n17 B     g       101  118.   140 16.2 \r\n18 B     h       122  133.   145 10.4 \r\n19 B     i       107  123.   139 15.2 \r\n20 B     j       109  128.   142 12.7 \r\n\r\n\r\n\r\ndf %>% \r\n  select(b, c, d) %>% \r\n  mutate(e = d*0.87) %>% \r\n  group_by(c, b) %>% \r\n  summarise(\r\n    'avg' = round(mean(e),2), .groups = 'keep'\r\n  ) %>% \r\n  glimpse()\r\n\r\n\r\nRows: 20\r\nColumns: 3\r\nGroups: c, b [20]\r\n$ c   <chr> \"A\", \"A\", \"A\", \"A\", \"A\", \"A\", \"A\", \"A\", \"A\", \"A\", \"B\", \"~\r\n$ b   <chr> \"a\", \"b\", \"c\", \"d\", \"e\", \"f\", \"g\", \"h\", \"i\", \"j\", \"a\", \"~\r\n$ avg <dbl> 119.62, 102.95, 113.62, 100.63, 111.98, 101.27, 111.53, ~\r\n\r\nTricks to do with dplyr\r\nRemove variables\r\n\r\n\r\ndf %>% \r\n  select(-b) %>% \r\n  head(10)\r\n\r\n\r\n    a c   d\r\n1   1 A 137\r\n2   2 A 145\r\n3   3 A 131\r\n4   4 A 106\r\n5   5 A 126\r\n6   6 A 141\r\n7   7 A 104\r\n8   8 A 105\r\n9   9 A 115\r\n10 10 A 123\r\n\r\nRe-Order Columns\r\n\r\n\r\ndf %>% \r\n  select(c, b, a, d) %>% \r\n  head(10)\r\n\r\n\r\n   c b  a   d\r\n1  A c  1 137\r\n2  A c  2 145\r\n3  A j  3 131\r\n4  A b  4 106\r\n5  A f  5 126\r\n6  A e  6 141\r\n7  A d  7 104\r\n8  A f  8 105\r\n9  A i  9 115\r\n10 A j 10 123\r\n\r\nRename variables\r\n\r\n\r\ndf %>% \r\n  select(a, c, b, d) %>% \r\n  rename('ID' = a,\r\n         'Class' = c,\r\n         'Subclass' = b,\r\n         'Attribute' = d) %>% \r\n  head(10)\r\n\r\n\r\n   ID Class Subclass Attribute\r\n1   1     A        c       137\r\n2   2     A        c       145\r\n3   3     A        j       131\r\n4   4     A        b       106\r\n5   5     A        f       126\r\n6   6     A        e       141\r\n7   7     A        d       104\r\n8   8     A        f       105\r\n9   9     A        i       115\r\n10 10     A        j       123\r\n\r\nSelect using text {regexp}\r\n\r\n\r\ndf %>% \r\n  select(a, c, b, d) %>% \r\n  rename('alpha-a' = a,\r\n         'alpha-b' = c,\r\n         'beta-a' = b,\r\n         'beta-b' = d) %>% \r\n  select(starts_with('alpha')) %>% \r\n  head(10)\r\n\r\n\r\n   alpha-a alpha-b\r\n1        1       A\r\n2        2       A\r\n3        3       A\r\n4        4       A\r\n5        5       A\r\n6        6       A\r\n7        7       A\r\n8        8       A\r\n9        9       A\r\n10      10       A\r\n\r\n\r\n\r\ndf %>% \r\n  select(a, c, b, d) %>% \r\n  rename('alpha-a' = a,\r\n         'alpha-b' = c,\r\n         'beta-a' = b,\r\n         'beta-b' = d) %>% \r\n  select(ends_with('a')) %>% \r\n  head(10)\r\n\r\n\r\n   alpha-a beta-a\r\n1        1      c\r\n2        2      c\r\n3        3      j\r\n4        4      b\r\n5        5      f\r\n6        6      e\r\n7        7      d\r\n8        8      f\r\n9        9      i\r\n10      10      j\r\n\r\n\r\n\r\ndf %>% \r\n  select_if(is.character)\r\n\r\n\r\n    b c\r\n1   c A\r\n2   c A\r\n3   j A\r\n4   b A\r\n5   f A\r\n6   e A\r\n7   d A\r\n8   f A\r\n9   i A\r\n10  j A\r\n11  e A\r\n12  c A\r\n13  i A\r\n14  i A\r\n15  i A\r\n16  c A\r\n17  h A\r\n18  j A\r\n19  g A\r\n20  j A\r\n21  i A\r\n22  c A\r\n23  d A\r\n24  a A\r\n25  g A\r\n26  e A\r\n27  j A\r\n28  g A\r\n29  i A\r\n30  i A\r\n31  j A\r\n32  g A\r\n33  e A\r\n34  g A\r\n35  e A\r\n36  f A\r\n37  i A\r\n38  b A\r\n39  e A\r\n40  h A\r\n41  b A\r\n42  a A\r\n43  i A\r\n44  i A\r\n45  f A\r\n46  e A\r\n47  i A\r\n48  j A\r\n49  d A\r\n50  f A\r\n51  h B\r\n52  f B\r\n53  f B\r\n54  g B\r\n55  a B\r\n56  f B\r\n57  b B\r\n58  a B\r\n59  b B\r\n60  d B\r\n61  e B\r\n62  f B\r\n63  c B\r\n64  i B\r\n65  d B\r\n66  f B\r\n67  i B\r\n68  i B\r\n69  g B\r\n70  c B\r\n71  h B\r\n72  i B\r\n73  c B\r\n74  g B\r\n75  c B\r\n76  g B\r\n77  f B\r\n78  j B\r\n79  e B\r\n80  e B\r\n81  h B\r\n82  c B\r\n83  j B\r\n84  b B\r\n85  j B\r\n86  b B\r\n87  j B\r\n88  f B\r\n89  d B\r\n90  a B\r\n91  f B\r\n92  c B\r\n93  h B\r\n94  c B\r\n95  h B\r\n96  a B\r\n97  g B\r\n98  g B\r\n99  g B\r\n100 j B\r\n\r\n\r\n\r\ndf %>% \r\n  group_by(c) %>% \r\n  arrange(c, desc(d))\r\n\r\n\r\n# A tibble: 100 x 4\r\n# Groups:   c [2]\r\n       a b     c         d\r\n   <int> <chr> <chr> <int>\r\n 1    46 e     A       148\r\n 2    24 a     A       147\r\n 3    38 b     A       147\r\n 4    27 j     A       146\r\n 5     2 c     A       145\r\n 6    16 c     A       145\r\n 7    15 i     A       143\r\n 8    44 i     A       143\r\n 9     6 e     A       141\r\n10    47 i     A       141\r\n# ... with 90 more rows\r\n\r\n\r\n\r\n\r\n",
      "last_modified": "2022-02-16T13:01:16+05:30"
    },
    {
      "path": "index.html",
      "title": "ouR - academy",
      "description": "_ouR-academy empowers people to solve hard problems, to understand their domain and fill with technology and skilled solution. ouR-academy believes data is the key to a better tomorrow and today, in association with our customers, we build new inspiring solutions. ouR-academy was founded with a core team that spanned Social Science and software enthusiast, cutting edge data science, Machine Learning Experts professionals. ouR-academy has advanced AI backed process, and now it also brings to market the most powerful and accessible Shiny Apps to elegantly solve some of the most complex data challenges, with impact, confidence, and passion._\n",
      "author": [],
      "contents": "\r\n  \r\n  \r\n \r\n\r\n\r\n\r\n",
      "last_modified": "2022-02-16T13:01:17+05:30"
    },
    {
      "path": "lubridate.html",
      "title": "Lubridate",
      "author": [],
      "contents": "\r\n\r\n\r\nlibrary(lubridate)\r\n\r\n\r\n\r\n\r\n\r\ndt <- c('20141224', '20141225', '20141230')\r\n\r\n\r\ndt <- ymd(dt)\r\n\r\ndt\r\n\r\n\r\n[1] \"2014-12-24\" \"2014-12-25\" \"2014-12-30\"\r\n\r\nWe can always convert string into date format using ymd(), mdy() and dmy() functions. Whatever the format is we can use any of them depends upon format we have in the string. For wrong function this will provide NAs most of the time.\r\n\r\n\r\ndmy(dt);mdy(dt)\r\n\r\n\r\n[1] NA NA NA\r\n[1] NA NA NA\r\n\r\n\r\n\r\ntoday()\r\n\r\n\r\n[1] \"2022-02-16\"\r\n\r\nnow()\r\n\r\n\r\n[1] \"2022-02-16 13:01:18 IST\"\r\n\r\n\r\n\r\nymd_h('2021122308')\r\n\r\n\r\n[1] \"2021-12-23 08:00:00 UTC\"\r\n\r\nymd_hm('202112230830')\r\n\r\n\r\n[1] \"2021-12-23 08:30:00 UTC\"\r\n\r\nymd_hms('20211223083022')\r\n\r\n\r\n[1] \"2021-12-23 08:30:22 UTC\"\r\n\r\nAbove can be manipulate like mdy or dmy, however always remember to write correct format.\r\n\r\n\r\nday <- 30L\r\nmonth <- 12L\r\nyear <- 2021L\r\n\r\nhour <- 12L\r\nminute <- 30L\r\nseconds <- 30L\r\n\r\n\r\ndt <- make_date(year, month, day)\r\ndt\r\n\r\n\r\n[1] \"2021-12-30\"\r\n\r\n\r\n\r\ndt <- make_datetime(year, month, day, hour, minute, seconds)\r\ndt\r\n\r\n\r\n[1] \"2021-12-30 12:30:30 UTC\"\r\n\r\nwe can always convert datetime into date and vice-versa.\r\n\r\n\r\ndt <- as_date(dt)\r\ndt\r\n\r\n\r\n[1] \"2021-12-30\"\r\n\r\n\r\n\r\ndt <- as_datetime(dt)\r\ndt\r\n\r\n\r\n[1] \"2021-12-30 UTC\"\r\n\r\nWe have accessor functions to pull components from a datetime using proper functions in lubridate:\r\n- year()\r\n- month()\r\n- mday() Day of the month\r\n- yday() Day of the year \r\n- wday() Day of the week\r\n- hour()\r\n- minute()\r\n- second() end.\r\n\r\n\r\nyear(dt)\r\n\r\n\r\n[1] 2021\r\n\r\nmonth(dt, label = TRUE)\r\n\r\n\r\n[1] Dec\r\n12 Levels: Jan < Feb < Mar < Apr < May < Jun < Jul < Aug < ... < Dec\r\n\r\nwday(dt, label = TRUE)\r\n\r\n\r\n[1] Thu\r\nLevels: Sun < Mon < Tue < Wed < Thu < Fri < Sat\r\n\r\nyday(dt)\r\n\r\n\r\n[1] 364\r\n\r\nmday(dt)\r\n\r\n\r\n[1] 30\r\n\r\nNOTE: We can also alter date components using this function.\r\n\r\n\r\nhour(dt)\r\n\r\n\r\n[1] 0\r\n\r\nminute(dt)\r\n\r\n\r\n[1] 0\r\n\r\nsecond(dt)\r\n\r\n\r\n[1] 0\r\n\r\nNOTE: We can alter date using the same functions\r\n\r\n\r\ndt <- seq(from = as_date(dt),\r\n                 to = as_date(dt) + 365,\r\n                 by = 1)\r\ndt\r\n\r\n\r\n  [1] \"2021-12-30\" \"2021-12-31\" \"2022-01-01\" \"2022-01-02\" \"2022-01-03\"\r\n  [6] \"2022-01-04\" \"2022-01-05\" \"2022-01-06\" \"2022-01-07\" \"2022-01-08\"\r\n [11] \"2022-01-09\" \"2022-01-10\" \"2022-01-11\" \"2022-01-12\" \"2022-01-13\"\r\n [16] \"2022-01-14\" \"2022-01-15\" \"2022-01-16\" \"2022-01-17\" \"2022-01-18\"\r\n [21] \"2022-01-19\" \"2022-01-20\" \"2022-01-21\" \"2022-01-22\" \"2022-01-23\"\r\n [26] \"2022-01-24\" \"2022-01-25\" \"2022-01-26\" \"2022-01-27\" \"2022-01-28\"\r\n [31] \"2022-01-29\" \"2022-01-30\" \"2022-01-31\" \"2022-02-01\" \"2022-02-02\"\r\n [36] \"2022-02-03\" \"2022-02-04\" \"2022-02-05\" \"2022-02-06\" \"2022-02-07\"\r\n [41] \"2022-02-08\" \"2022-02-09\" \"2022-02-10\" \"2022-02-11\" \"2022-02-12\"\r\n [46] \"2022-02-13\" \"2022-02-14\" \"2022-02-15\" \"2022-02-16\" \"2022-02-17\"\r\n [51] \"2022-02-18\" \"2022-02-19\" \"2022-02-20\" \"2022-02-21\" \"2022-02-22\"\r\n [56] \"2022-02-23\" \"2022-02-24\" \"2022-02-25\" \"2022-02-26\" \"2022-02-27\"\r\n [61] \"2022-02-28\" \"2022-03-01\" \"2022-03-02\" \"2022-03-03\" \"2022-03-04\"\r\n [66] \"2022-03-05\" \"2022-03-06\" \"2022-03-07\" \"2022-03-08\" \"2022-03-09\"\r\n [71] \"2022-03-10\" \"2022-03-11\" \"2022-03-12\" \"2022-03-13\" \"2022-03-14\"\r\n [76] \"2022-03-15\" \"2022-03-16\" \"2022-03-17\" \"2022-03-18\" \"2022-03-19\"\r\n [81] \"2022-03-20\" \"2022-03-21\" \"2022-03-22\" \"2022-03-23\" \"2022-03-24\"\r\n [86] \"2022-03-25\" \"2022-03-26\" \"2022-03-27\" \"2022-03-28\" \"2022-03-29\"\r\n [91] \"2022-03-30\" \"2022-03-31\" \"2022-04-01\" \"2022-04-02\" \"2022-04-03\"\r\n [96] \"2022-04-04\" \"2022-04-05\" \"2022-04-06\" \"2022-04-07\" \"2022-04-08\"\r\n[101] \"2022-04-09\" \"2022-04-10\" \"2022-04-11\" \"2022-04-12\" \"2022-04-13\"\r\n[106] \"2022-04-14\" \"2022-04-15\" \"2022-04-16\" \"2022-04-17\" \"2022-04-18\"\r\n[111] \"2022-04-19\" \"2022-04-20\" \"2022-04-21\" \"2022-04-22\" \"2022-04-23\"\r\n[116] \"2022-04-24\" \"2022-04-25\" \"2022-04-26\" \"2022-04-27\" \"2022-04-28\"\r\n[121] \"2022-04-29\" \"2022-04-30\" \"2022-05-01\" \"2022-05-02\" \"2022-05-03\"\r\n[126] \"2022-05-04\" \"2022-05-05\" \"2022-05-06\" \"2022-05-07\" \"2022-05-08\"\r\n[131] \"2022-05-09\" \"2022-05-10\" \"2022-05-11\" \"2022-05-12\" \"2022-05-13\"\r\n[136] \"2022-05-14\" \"2022-05-15\" \"2022-05-16\" \"2022-05-17\" \"2022-05-18\"\r\n[141] \"2022-05-19\" \"2022-05-20\" \"2022-05-21\" \"2022-05-22\" \"2022-05-23\"\r\n[146] \"2022-05-24\" \"2022-05-25\" \"2022-05-26\" \"2022-05-27\" \"2022-05-28\"\r\n[151] \"2022-05-29\" \"2022-05-30\" \"2022-05-31\" \"2022-06-01\" \"2022-06-02\"\r\n[156] \"2022-06-03\" \"2022-06-04\" \"2022-06-05\" \"2022-06-06\" \"2022-06-07\"\r\n[161] \"2022-06-08\" \"2022-06-09\" \"2022-06-10\" \"2022-06-11\" \"2022-06-12\"\r\n[166] \"2022-06-13\" \"2022-06-14\" \"2022-06-15\" \"2022-06-16\" \"2022-06-17\"\r\n[171] \"2022-06-18\" \"2022-06-19\" \"2022-06-20\" \"2022-06-21\" \"2022-06-22\"\r\n[176] \"2022-06-23\" \"2022-06-24\" \"2022-06-25\" \"2022-06-26\" \"2022-06-27\"\r\n[181] \"2022-06-28\" \"2022-06-29\" \"2022-06-30\" \"2022-07-01\" \"2022-07-02\"\r\n[186] \"2022-07-03\" \"2022-07-04\" \"2022-07-05\" \"2022-07-06\" \"2022-07-07\"\r\n[191] \"2022-07-08\" \"2022-07-09\" \"2022-07-10\" \"2022-07-11\" \"2022-07-12\"\r\n[196] \"2022-07-13\" \"2022-07-14\" \"2022-07-15\" \"2022-07-16\" \"2022-07-17\"\r\n[201] \"2022-07-18\" \"2022-07-19\" \"2022-07-20\" \"2022-07-21\" \"2022-07-22\"\r\n[206] \"2022-07-23\" \"2022-07-24\" \"2022-07-25\" \"2022-07-26\" \"2022-07-27\"\r\n[211] \"2022-07-28\" \"2022-07-29\" \"2022-07-30\" \"2022-07-31\" \"2022-08-01\"\r\n[216] \"2022-08-02\" \"2022-08-03\" \"2022-08-04\" \"2022-08-05\" \"2022-08-06\"\r\n[221] \"2022-08-07\" \"2022-08-08\" \"2022-08-09\" \"2022-08-10\" \"2022-08-11\"\r\n[226] \"2022-08-12\" \"2022-08-13\" \"2022-08-14\" \"2022-08-15\" \"2022-08-16\"\r\n[231] \"2022-08-17\" \"2022-08-18\" \"2022-08-19\" \"2022-08-20\" \"2022-08-21\"\r\n[236] \"2022-08-22\" \"2022-08-23\" \"2022-08-24\" \"2022-08-25\" \"2022-08-26\"\r\n[241] \"2022-08-27\" \"2022-08-28\" \"2022-08-29\" \"2022-08-30\" \"2022-08-31\"\r\n[246] \"2022-09-01\" \"2022-09-02\" \"2022-09-03\" \"2022-09-04\" \"2022-09-05\"\r\n[251] \"2022-09-06\" \"2022-09-07\" \"2022-09-08\" \"2022-09-09\" \"2022-09-10\"\r\n[256] \"2022-09-11\" \"2022-09-12\" \"2022-09-13\" \"2022-09-14\" \"2022-09-15\"\r\n[261] \"2022-09-16\" \"2022-09-17\" \"2022-09-18\" \"2022-09-19\" \"2022-09-20\"\r\n[266] \"2022-09-21\" \"2022-09-22\" \"2022-09-23\" \"2022-09-24\" \"2022-09-25\"\r\n[271] \"2022-09-26\" \"2022-09-27\" \"2022-09-28\" \"2022-09-29\" \"2022-09-30\"\r\n[276] \"2022-10-01\" \"2022-10-02\" \"2022-10-03\" \"2022-10-04\" \"2022-10-05\"\r\n[281] \"2022-10-06\" \"2022-10-07\" \"2022-10-08\" \"2022-10-09\" \"2022-10-10\"\r\n[286] \"2022-10-11\" \"2022-10-12\" \"2022-10-13\" \"2022-10-14\" \"2022-10-15\"\r\n[291] \"2022-10-16\" \"2022-10-17\" \"2022-10-18\" \"2022-10-19\" \"2022-10-20\"\r\n[296] \"2022-10-21\" \"2022-10-22\" \"2022-10-23\" \"2022-10-24\" \"2022-10-25\"\r\n[301] \"2022-10-26\" \"2022-10-27\" \"2022-10-28\" \"2022-10-29\" \"2022-10-30\"\r\n[306] \"2022-10-31\" \"2022-11-01\" \"2022-11-02\" \"2022-11-03\" \"2022-11-04\"\r\n[311] \"2022-11-05\" \"2022-11-06\" \"2022-11-07\" \"2022-11-08\" \"2022-11-09\"\r\n[316] \"2022-11-10\" \"2022-11-11\" \"2022-11-12\" \"2022-11-13\" \"2022-11-14\"\r\n[321] \"2022-11-15\" \"2022-11-16\" \"2022-11-17\" \"2022-11-18\" \"2022-11-19\"\r\n[326] \"2022-11-20\" \"2022-11-21\" \"2022-11-22\" \"2022-11-23\" \"2022-11-24\"\r\n[331] \"2022-11-25\" \"2022-11-26\" \"2022-11-27\" \"2022-11-28\" \"2022-11-29\"\r\n[336] \"2022-11-30\" \"2022-12-01\" \"2022-12-02\" \"2022-12-03\" \"2022-12-04\"\r\n[341] \"2022-12-05\" \"2022-12-06\" \"2022-12-07\" \"2022-12-08\" \"2022-12-09\"\r\n[346] \"2022-12-10\" \"2022-12-11\" \"2022-12-12\" \"2022-12-13\" \"2022-12-14\"\r\n[351] \"2022-12-15\" \"2022-12-16\" \"2022-12-17\" \"2022-12-18\" \"2022-12-19\"\r\n[356] \"2022-12-20\" \"2022-12-21\" \"2022-12-22\" \"2022-12-23\" \"2022-12-24\"\r\n[361] \"2022-12-25\" \"2022-12-26\" \"2022-12-27\" \"2022-12-28\" \"2022-12-29\"\r\n[366] \"2022-12-30\"\r\n\r\nWe can set nearby dates for plotting using floor_date, round_date and ceiling_date functions.\r\nPeriods\r\n\r\n\r\ndt[2]\r\n\r\n\r\n[1] \"2021-12-31\"\r\n\r\ndt[2] + years(1) + months(1) + days(1)\r\n\r\n\r\n[1] \"2023-02-01\"\r\n\r\nThe End\r\n\r\n\r\n\r\n",
      "last_modified": "2022-02-16T13:01:20+05:30"
    },
    {
      "path": "plot.html",
      "title": "Basics of Plots in R",
      "author": [],
      "contents": "\r\n\r\nContents\r\n\r\n\r\nPlot\r\n\r\n\r\nx <- 1:20 \r\ny <- x*0.8 + rnorm(20)\r\nplot(x, y)\r\n\r\n\r\n\r\n\r\nLabel for plot\r\nWe do labeling in R base using xlab and ylab function.Example is a given below, here we have given names as follows: ‘X-axis’ and ‘Y-axis’\r\n\r\n\r\nx <- 1:20 \r\ny <- x*0.8 + rnorm(20)\r\nplot(x, y, xlab = 'X-axis', ylab = 'Y-axis')\r\n\r\n\r\n\r\n\r\nTitle And Subtitle in plots\r\nWe use main and sub function for giving title in the plot at the same time we can caption the graph using caption function in R. As given below.\r\n\r\n\r\nx <- 1:20 \r\ny <- x*0.8 + rnorm(20)\r\nplot(x, y, xlab = 'X-axis', ylab = 'Y-axis', main = 'Title', sub = 'Sub-Title')\r\n\r\n\r\n\r\n\r\nShape, Size and Color for coordinates\r\nShape of the coordinates are managed by pch arguments in R as shown below. cex argument takes care of the size of coordinates type, you can change value to have fun. Similarly col function provide color to the pch types. On the same, One can get help from R using either ?pch or help(pch).\r\n\r\n\r\nx <- 1:20 \r\ny <- x*0.8 + rnorm(20)\r\nplot(x, y, xlab = 'X-axis', ylab = 'Y-axis', main = 'Title', sub = 'Sub-Title', pch = 2, cex = 1.5, col = 'green')\r\n\r\n\r\n\r\n\r\nType Of Plot\r\nType argument is plot function provide different kind of plotting options. Which are as follows:\r\nwhat type of plot should be drawn. Possible types are\r\n“p” for points,\r\n“l” for lines,\r\n“b” for both,\r\n“c” for the lines part alone of “b”,\r\n“o” for both ‘overplotted’,\r\n“h” for ‘histogram’ like (or ‘high-density’) vertical lines,\r\n“s” for stair steps,\r\n“S” for other steps, see ‘Details’ below,\r\n“n” for no plotting.\r\n\r\n\r\nx <- 1:20 \r\ny <- x*0.8 + rnorm(20)\r\nplot(x, y, xlab = 'X-axis', ylab = 'Y-axis',\r\n     main = 'Title', sub = 'Sub-Title', \r\n     pch = 2, cex = 1.5, col = 'green',\r\n     type = 'o')\r\n\r\n\r\n\r\n\r\n\r\nNOTE: Plot is function is a generic function in R, where you can plot any possible graph using it. Though packages are available for high level plotting. But one must have knowledge of plot function because many machine learning plot can be done using it.\r\n\r\n\r\n\r\na <- rnorm(1000)\r\nhist(a, breaks = 30,col = 'blue', \r\n     xlab = '', ylab = '', main = '')\r\n\r\n\r\n\r\n\r\nBar plot in R is hunky dory work. All we need is count of a particular vector which is either character or factor. Than barplot function plot it.\r\n\r\n\r\nset.seed(143)\r\nx <- sample(letters[1:4],100, replace = T)\r\n\r\nbarplot(table(x),\r\n        names.arg = c(LETTERS[1:4]),\r\n        horiz = T,\r\n        col = 'darkred',\r\n        cex.names =  1.5, \r\n        axes = F,\r\n        border = 'red',\r\n        density = 12)\r\n\r\n\r\n\r\n\r\nPie Chart can be depicted by using pie function in R. It also requires frequency for the variable which we want to analyse.\r\n\r\n\r\npie(table(x),\r\n    labels = paste0(LETTERS[1:4],'-', table(x)),\r\n    #edges = 2,\r\n    main = \"pie(*, labels=\\\"\\\")\",\r\n    col = c('darkred', 'darkgreen', 'deepskyblue', 'blue'),\r\n    border = 'yellow')\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n",
      "last_modified": "2022-02-16T13:01:23+05:30"
    },
    {
      "path": "ply.html",
      "title": "Apply Family",
      "author": [],
      "contents": "\r\napply family\r\nfirst we will go through a simple example of apply function and see how it is convenient.\r\n\r\n\r\nm <- matrix(1:25, 5, 5, byrow = T)\r\nm\r\n\r\n\r\n     [,1] [,2] [,3] [,4] [,5]\r\n[1,]    1    2    3    4    5\r\n[2,]    6    7    8    9   10\r\n[3,]   11   12   13   14   15\r\n[4,]   16   17   18   19   20\r\n[5,]   21   22   23   24   25\r\n\r\nlet say if one wants to calculate mean value for either each row or column. It will be tough and time consuming since one will have to do it manually for each column or will have to write a loop function. But since apply function is there to save us from all of this.\r\n\r\n\r\napply(m, 2, mean) # for each column\r\n\r\n\r\n[1] 11 12 13 14 15\r\n\r\napply(m, 1, mean)\r\n\r\n\r\n[1]  3  8 13 18 23\r\n\r\nsee how eazy peezy!\r\nNOTE: apply function requires three arguments which are data.frame/matrix, next if operation has to be done row wise or column wise {1 or 2 respectively.} and lastly the function, in our case, its mean. We can use function instead.\r\nlapply function\r\nL-apply is one of famous member of apply family. It deals with list objects and returns list as well. It requires two objects first is a list of objects and then the function.\r\nSo we have simple example to understand this.\r\n\r\n\r\na <- c(5,10,15)\r\nb <- c(10,100,1000)\r\n\r\nl <- list(a, b)\r\nlapply(l,  mean)\r\n\r\n\r\n[[1]]\r\n[1] 10\r\n\r\n[[2]]\r\n[1] 370\r\n\r\nAnd a more complex example is here.\r\n\r\n\r\nl2 <- list(m, a)\r\n\r\nlapply(l2, sum)\r\n\r\n\r\n[[1]]\r\n[1] 325\r\n\r\n[[2]]\r\n[1] 30\r\n\r\n:) Wonderful! We have just seen lapply not only deals with lists it can also use with different kind of list objects such as one is matrix and another one is a vector. We can also use different matrix and apply function for each using lapply.\r\nsapply\r\nIt functions same as lapply except it produces vector of result rather than a list\r\n\r\n\r\nsapply(l2, sum)\r\n\r\n\r\n[1] 325  30\r\n\r\ntapply\r\nIt is a really interesting and very much useful from the perpective of categorical variable attribute finding.\r\n\r\n\r\ndf <- data.frame(\r\n'sex' = c('M', 'F', 'M', 'O', 'O', 'F'),\r\n'income' = c(100,200,300,400,500,600)\r\n)\r\n\r\ntapply(df$income, df$sex, mean)\r\n\r\n\r\n  F   M   O \r\n400 200 450 \r\n\r\nTa Da! See We are done with this part. Hope to see you on the next learning page.\r\n\r\n\r\n\r\n",
      "last_modified": "2022-02-16T13:01:25+05:30"
    },
    {
      "path": "purrr.html",
      "title": "purrr",
      "author": [],
      "contents": "\r\n\r\n\r\nlibrary(purrr)\r\nlibrary(dplyr)\r\nlibrary(tibble)\r\n\r\n\r\n\r\n\r\n\r\ndf <- data.frame(\r\n  a = rnorm(50),\r\n  b = rnorm(50),\r\n  c = rnorm(50),\r\n  d = rnorm(50)\r\n)\r\n\r\n\r\n\r\n\r\n\r\nvec <- vector(mode = 'double', length = ncol(df))\r\nfor(col in seq_along(df)){\r\n  vec[[col]] <- mean(df[, col])\r\n}\r\n\r\nvec\r\n\r\n\r\n[1]  0.1139517  0.1027821  0.1203338 -0.1898205\r\n\r\n\r\n\r\nrescale01 <- function(array){\r\n  # min <- min(array)\r\n  # max <- max(array)\r\n  rng <- range(array)\r\n  (array - rng[1])/(rng[2] - rng[1])\r\n}\r\n\r\n\r\n\r\n\r\n\r\nfor (col in seq_along(df)) {\r\n  df[col] <- rescale01(df[[col]])\r\n}\r\n\r\n\r\n\r\n\r\n\r\nset.seed(123)\r\nflip <- function() sample(c(\"H\", \"T\"), 1, prob = c(0.5, 0.5))\r\n\r\n\r\nflips <- 0\r\nnheads <- 0\r\n\r\nwhile(nheads < 5){ # Five heads in a row\r\n  if(flip() == 'H'){\r\n    nheads <- nheads + 1\r\n  } else {\r\n    nheads <- 0\r\n  }\r\n  flips <- flips + 1\r\n}\r\n\r\nflips\r\n\r\n\r\n[1] 24\r\n\r\n\r\n\r\nmedian_vec <- function(db1){\r\n  \r\n  medians <- vector('double', length(db1))\r\n  \r\n  for(col in seq_along(db1)){\r\n    medians[[col]] <- median(db1[[col]], na.rm = T)\r\n  }\r\n  medians\r\n}\r\n\r\n\r\nmedian_vec(df)\r\n\r\n\r\n[1] 0.5405315 0.4683460 0.4304072 0.3732386\r\n\r\n\r\n\r\nmap(df, mean)\r\n\r\n\r\n$a\r\n[1] 0.5397286\r\n\r\n$b\r\n[1] 0.4888124\r\n\r\n$c\r\n[1] 0.4186424\r\n\r\n$d\r\n[1] 0.3928152\r\n\r\n\r\n\r\nmap_dbl(df, mean)\r\n\r\n\r\n        a         b         c         d \r\n0.5397286 0.4888124 0.4186424 0.3928152 \r\n\r\n\r\n\r\nmodels <- mtcars %>% \r\n  split(.$cyl) %>% \r\n  map(function(db) lm(mpg~wt, data = db)) \r\n\r\n\r\n\r\n\r\n\r\nmodels %>% \r\n  map(summary) %>% \r\n  map_dbl(~.$r.squared)\r\n\r\n\r\n        4         6         8 \r\n0.5086326 0.4645102 0.4229655 \r\n\r\n\r\n\r\nmodels %>% \r\n  map(summary) %>% \r\n  map_dbl(\"adj.r.squared\")\r\n\r\n\r\n        4         6         8 \r\n0.4540362 0.3574122 0.3748793 \r\n\r\n\r\n\r\nm <- c(5,10,15)\r\n\r\nm %>% \r\n  map(rnorm, n = 10) %>% \r\n  str()\r\n\r\n\r\nList of 3\r\n $ : num [1:10] 5.4 5.11 4.44 6.79 5.5 ...\r\n $ : num [1:10] 8.97 9.27 9.37 8.31 10.84 ...\r\n $ : num [1:10] 15.9 15.9 15.8 15.7 15.6 ...\r\n\r\n\r\n\r\nsd <- c(1.5, 2.0, 2.5)\r\n\r\nlist(m, sd) %>% \r\n  map(rnorm, n = 10)\r\n\r\n\r\n[[1]]\r\n [1]  3.734604 12.168956 16.207962  3.876891  9.597115 14.533345\r\n [7]  5.779965  9.916631 15.253319  4.971453\r\n\r\n[[2]]\r\n [1] 1.4571295 3.3686023 2.2742290 3.0164706 0.4512472 3.0846137\r\n [7] 1.6238542 2.2159416 2.8796395 0.9976765\r\n\r\n\r\n\r\nmap2(m, sd, rnorm, n = 15) %>% \r\n  str()\r\n\r\n\r\nList of 3\r\n $ : num [1:15] 4.5 3.47 3.39 5.46 5.67 ...\r\n $ : num [1:15] 7.56 10.36 9.72 10.01 10.77 ...\r\n $ : num [1:15] 15.6 13.4 18.4 13.5 20.5 ...\r\n\r\n\r\n\r\nn <- c(10, 50, 100)\r\n\r\nlist(n, m, sd) %>% \r\n  pmap(rnorm) %>% \r\n  str()\r\n\r\n\r\nList of 3\r\n $ : num [1:10] 2.5 4.43 6.38 4.14 5.91 ...\r\n $ : num [1:50] 8.72 8.3 7.95 10.24 8.11 ...\r\n $ : num [1:100] 13.8 16.3 15.9 14.5 15.2 ...\r\n\r\n\r\n\r\nf <- c('runif', 'rnorm', 'rpois')\r\n\r\nprm <- list(\r\n  list(min = 5, max = 25),\r\n  list(m = 25, sd = 5),\r\n  list(lambda = 5)\r\n)\r\n\r\n\r\ninvoke_map(f, prm, n = 10) %>% str()\r\n\r\n\r\nList of 3\r\n $ : num [1:10] 5.79 19.78 11.97 21.59 15.71 ...\r\n $ : num [1:10] 28.4 18 29.2 22.8 25.9 ...\r\n $ : int [1:10] 6 6 4 7 5 8 5 8 5 4\r\n\r\n\r\n\r\ndf %>% \r\n  mutate(e = rep(c('A', 'B'), 25)) %>% \r\n  keep(is.numeric) %>% \r\n  str()\r\n\r\n\r\n'data.frame':   50 obs. of  4 variables:\r\n $ a: num  0.982 0.842 0 0.369 0.209 ...\r\n $ b: num  0.552 0.678 0.678 0.188 0.451 ...\r\n $ c: num  0.337 0.335 0.382 0.298 0.839 ...\r\n $ d: num  0.3643 0.0942 0.171 0.6978 0.6081 ...\r\n\r\n\r\n\r\ndf %>% \r\n  mutate(e = rep(c('A', 'B'), 25)) %>% \r\n  discard(is.numeric) %>% \r\n  str()\r\n\r\n\r\n'data.frame':   50 obs. of  1 variable:\r\n $ e: chr  \"A\" \"B\" \"A\" \"B\" ...\r\n\r\nWe can also use across(), some() and every(). There are more functions such as detect(), walk() and slice() which we can use in our analysis.\r\n\r\n\r\n\r\n",
      "last_modified": "2022-02-16T13:01:29+05:30"
    },
    {
      "path": "shinyapp.html",
      "title": "Shiny App Demo",
      "author": [],
      "contents": "\r\n\r\n\r\n\r\n\r\n\r\n",
      "last_modified": "2022-02-16T13:01:30+05:30"
    },
    {
      "path": "stringr.html",
      "title": "Stringr",
      "author": [],
      "contents": "\r\nText package from tidyverse family in R\r\n\r\n\r\n#install.packages('stringr')\r\nlibrary(stringr)\r\n\r\n\r\n\r\nstr_c\r\nstr_sub\r\nstr_to_lower -or- str_to_upper -or- str_to_title\r\nand many more!\r\n\r\n\r\nprint(\"Welcome to no man's land\")\r\n\r\n\r\n[1] \"Welcome to no man's land\"\r\n\r\n\r\n\r\nstr <- c('apple', 'banana', 'pear')\r\nstr_view(str, 'an')\r\n\r\n\r\n\r\n{\"x\":{\"html\":\"<ul>\\n  <li>apple<\\/li>\\n  <li>b<span class='match'>an<\\/span>ana<\\/li>\\n  <li>pear<\\/li>\\n<\\/ul>\"},\"evals\":[],\"jsHooks\":[]}\r\n\r\n\r\nstr_view(str, '.an.')\r\n\r\n\r\n\r\n{\"x\":{\"html\":\"<ul>\\n  <li>apple<\\/li>\\n  <li><span class='match'>bana<\\/span>na<\\/li>\\n  <li>pear<\\/li>\\n<\\/ul>\"},\"evals\":[],\"jsHooks\":[]}\r\n\r\n\r\nstr_view(c('apple', 'ban.na', 'pear'), 'n.')\r\n\r\n\r\n\r\n{\"x\":{\"html\":\"<ul>\\n  <li>apple<\\/li>\\n  <li>ba<span class='match'>n.<\\/span>na<\\/li>\\n  <li>pear<\\/li>\\n<\\/ul>\"},\"evals\":[],\"jsHooks\":[]}\r\nstr_view(c('apple', 'ban.na', 'pear'), 'n\\\\.')\r\n\r\n\r\n\r\n{\"x\":{\"html\":\"<ul>\\n  <li>apple<\\/li>\\n  <li>ba<span class='match'>n.<\\/span>na<\\/li>\\n  <li>pear<\\/li>\\n<\\/ul>\"},\"evals\":[],\"jsHooks\":[]}\r\n\r\n\r\nnewline <- \"\\\\.\"\r\nwriteLines(newline)\r\n\r\n\r\n\\.\r\n\r\nstr_view(c(str, newline), '\\\\.')\r\n\r\n\r\n\r\n{\"x\":{\"html\":\"<ul>\\n  <li>apple<\\/li>\\n  <li>banana<\\/li>\\n  <li>pear<\\/li>\\n  <li>\\\\<span class='match'>.<\\/span><\\/li>\\n<\\/ul>\"},\"evals\":[],\"jsHooks\":[]}\r\nstr_view(c(str, newline), '\\\\\\\\.')\r\n\r\n\r\n\r\n{\"x\":{\"html\":\"<ul>\\n  <li>apple<\\/li>\\n  <li>banana<\\/li>\\n  <li>pear<\\/li>\\n  <li><span class='match'>\\\\.<\\/span><\\/li>\\n<\\/ul>\"},\"evals\":[],\"jsHooks\":[]}\r\n\r\n\r\nstr_view(str, '^b')\r\n\r\n\r\n\r\n{\"x\":{\"html\":\"<ul>\\n  <li>apple<\\/li>\\n  <li><span class='match'>b<\\/span>anana<\\/li>\\n  <li>pear<\\/li>\\n<\\/ul>\"},\"evals\":[],\"jsHooks\":[]}\r\nstr_view(str, 'a$')\r\n\r\n\r\n\r\n{\"x\":{\"html\":\"<ul>\\n  <li>apple<\\/li>\\n  <li>banan<span class='match'>a<\\/span><\\/li>\\n  <li>pear<\\/li>\\n<\\/ul>\"},\"evals\":[],\"jsHooks\":[]}\r\n\r\n\r\nstr_view(str, '^ap')\r\n\r\n\r\n\r\n{\"x\":{\"html\":\"<ul>\\n  <li><span class='match'>ap<\\/span>ple<\\/li>\\n  <li>banana<\\/li>\\n  <li>pear<\\/li>\\n<\\/ul>\"},\"evals\":[],\"jsHooks\":[]}\r\nstr_view(str, 'le$')\r\n\r\n\r\n\r\n{\"x\":{\"html\":\"<ul>\\n  <li>app<span class='match'>le<\\/span><\\/li>\\n  <li>banana<\\/li>\\n  <li>pear<\\/li>\\n<\\/ul>\"},\"evals\":[],\"jsHooks\":[]}\r\n\r\n\r\napple <- c('apple pie', 'apple', 'apple-cake')\r\n\r\nstr_view(apple, '^apple$')\r\n\r\n\r\n\r\n{\"x\":{\"html\":\"<ul>\\n  <li>apple pie<\\/li>\\n  <li><span class='match'>apple<\\/span><\\/li>\\n  <li>apple-cake<\\/li>\\n<\\/ul>\"},\"evals\":[],\"jsHooks\":[]}\r\nstr_view(apple, '^apple-')\r\n\r\n\r\n\r\n{\"x\":{\"html\":\"<ul>\\n  <li>apple pie<\\/li>\\n  <li>apple<\\/li>\\n  <li><span class='match'>apple-<\\/span>cake<\\/li>\\n<\\/ul>\"},\"evals\":[],\"jsHooks\":[]}\r\nstr_view(apple, '^apple-$')\r\n\r\n\r\n\r\n{\"x\":{\"html\":\"<ul>\\n  <li>apple pie<\\/li>\\n  <li>apple<\\/li>\\n  <li>apple-cake<\\/li>\\n<\\/ul>\"},\"evals\":[],\"jsHooks\":[]}\r\n\r\n\r\nstr_view(str, '[apl]')\r\n\r\n\r\n\r\n{\"x\":{\"html\":\"<ul>\\n  <li><span class='match'>a<\\/span>pple<\\/li>\\n  <li>b<span class='match'>a<\\/span>nana<\\/li>\\n  <li><span class='match'>p<\\/span>ear<\\/li>\\n<\\/ul>\"},\"evals\":[],\"jsHooks\":[]}\r\nstr_view(str, '[^apl]')\r\n\r\n\r\n\r\n{\"x\":{\"html\":\"<ul>\\n  <li>appl<span class='match'>e<\\/span><\\/li>\\n  <li><span class='match'>b<\\/span>anana<\\/li>\\n  <li>p<span class='match'>e<\\/span>ar<\\/li>\\n<\\/ul>\"},\"evals\":[],\"jsHooks\":[]}\r\nstr_view(str, 'a(p|n|r)')\r\n\r\n\r\n\r\n{\"x\":{\"html\":\"<ul>\\n  <li><span class='match'>ap<\\/span>ple<\\/li>\\n  <li>b<span class='match'>an<\\/span>ana<\\/li>\\n  <li>pe<span class='match'>ar<\\/span><\\/li>\\n<\\/ul>\"},\"evals\":[],\"jsHooks\":[]}\r\n\r\n\r\nstr_view(apple, '\\\\s')\r\n\r\n\r\n\r\n{\"x\":{\"html\":\"<ul>\\n  <li>apple<span class='match'> <\\/span>pie<\\/li>\\n  <li>apple<\\/li>\\n  <li>apple-cake<\\/li>\\n<\\/ul>\"},\"evals\":[],\"jsHooks\":[]}\r\nstr_view(c('3rd', '+911', '10may'), '\\\\d')\r\n\r\n\r\n\r\n{\"x\":{\"html\":\"<ul>\\n  <li><span class='match'>3<\\/span>rd<\\/li>\\n  <li>+<span class='match'>9<\\/span>11<\\/li>\\n  <li><span class='match'>1<\\/span>0may<\\/li>\\n<\\/ul>\"},\"evals\":[],\"jsHooks\":[]}\r\nRepetition\r\n- ?: 0 or 1\r\n- +: 1 or more\r\n- *: 0 or more\r\n\r\n\r\nx <- \"we write 1888 in Roman as MDCCCLXXXVIII\"\r\n\r\nstr_view(x, \"CC?\")\r\n\r\n\r\n\r\n{\"x\":{\"html\":\"<ul>\\n  <li>we write 1888 in Roman as MD<span class='match'>CC<\\/span>CLXXXVIII<\\/li>\\n<\\/ul>\"},\"evals\":[],\"jsHooks\":[]}\r\n\r\n\r\nstr_view(x, \"CC+\")\r\n\r\n\r\n\r\n{\"x\":{\"html\":\"<ul>\\n  <li>we write 1888 in Roman as MD<span class='match'>CCC<\\/span>LXXXVIII<\\/li>\\n<\\/ul>\"},\"evals\":[],\"jsHooks\":[]}\r\n\r\n\r\nstr_view(x, \"C[LX]+\")\r\n\r\n\r\n\r\n{\"x\":{\"html\":\"<ul>\\n  <li>we write 1888 in Roman as MDCC<span class='match'>CLXXX<\\/span>VIII<\\/li>\\n<\\/ul>\"},\"evals\":[],\"jsHooks\":[]}\r\nSpecify the number of matches:\r\n-   {n}  : exactly n times\r\n-   {n,} : n or more\r\n-   {,m} : at most m\r\n-   {n,m}: between n and m\r\n\r\n\r\nstr_view(x, \"C{2}\")\r\n\r\n\r\n\r\n{\"x\":{\"html\":\"<ul>\\n  <li>we write 1888 in Roman as MD<span class='match'>CC<\\/span>CLXXXVIII<\\/li>\\n<\\/ul>\"},\"evals\":[],\"jsHooks\":[]}\r\nstr_view(x, \"C{2,3}\")\r\n\r\n\r\n\r\n{\"x\":{\"html\":\"<ul>\\n  <li>we write 1888 in Roman as MD<span class='match'>CCC<\\/span>LXXXVIII<\\/li>\\n<\\/ul>\"},\"evals\":[],\"jsHooks\":[]}\r\nstr_view(x, \"C{2,3}?\")  # ?: for shortest possible match\r\n\r\n\r\n\r\n{\"x\":{\"html\":\"<ul>\\n  <li>we write 1888 in Roman as MD<span class='match'>CC<\\/span>CLXXXVIII<\\/li>\\n<\\/ul>\"},\"evals\":[],\"jsHooks\":[]}\r\n\r\n\r\nstr_view(x, \"C[LX]+?\")\r\n\r\n\r\n\r\n{\"x\":{\"html\":\"<ul>\\n  <li>we write 1888 in Roman as MDCC<span class='match'>CL<\\/span>XXXVIII<\\/li>\\n<\\/ul>\"},\"evals\":[],\"jsHooks\":[]}\r\n\r\n\r\nstr_view(fruit, \"(..)\\\\1\", match = TRUE) \r\n\r\n\r\n\r\n{\"x\":{\"html\":\"<ul>\\n  <li>b<span class='match'>anan<\\/span>a<\\/li>\\n  <li><span class='match'>coco<\\/span>nut<\\/li>\\n  <li><span class='match'>cucu<\\/span>mber<\\/li>\\n  <li><span class='match'>juju<\\/span>be<\\/li>\\n  <li><span class='match'>papa<\\/span>ya<\\/li>\\n  <li>s<span class='match'>alal<\\/span> berry<\\/li>\\n<\\/ul>\"},\"evals\":[],\"jsHooks\":[]}\r\n# .'s are the key increase or decrease you will know\r\n\r\n\r\n\r\nDetect Matches\r\n\r\n\r\nstr_detect(str, \"e\")\r\n\r\n\r\n[1]  TRUE FALSE  TRUE\r\n\r\n\r\n\r\nsum(\r\nstr_detect(words, \"^a\")\r\n)\r\n\r\n\r\n[1] 65\r\n\r\n\r\n\r\nmean(\r\n    str_detect(words, \"^[aeiou]\")\r\n)\r\n\r\n\r\n[1] 0.1785714\r\n\r\n\r\n\r\nno_vowels <- !str_detect(words, \"[aeiou]\")\r\n\r\nno.vowels <- str_detect(words, \"^[^aeiou]+$\")\r\n\r\nidentical(no_vowels, no.vowels)\r\n\r\n\r\n[1] TRUE\r\n\r\n\r\n\r\nwords[str_detect(words, \"x$\")]\r\n\r\n\r\n[1] \"box\" \"sex\" \"six\" \"tax\"\r\n\r\nstr_subset(words, \"x$\")\r\n\r\n\r\n[1] \"box\" \"sex\" \"six\" \"tax\"\r\n\r\n\r\n\r\ntb <- data.frame(\r\n    seriel = seq_along(words),\r\n    word = words\r\n)\r\n\r\ntb %>% \r\n    tail()\r\n\r\n\r\n    seriel      word\r\n975    975      year\r\n976    976       yes\r\n977    977 yesterday\r\n978    978       yet\r\n979    979       you\r\n980    980     young\r\n\r\n\r\n\r\ntb %>% \r\n    dplyr::filter(str_detect(words, \"[xyz]$\"))\r\n\r\n\r\n   seriel        word\r\n1      31     already\r\n2      41         any\r\n3      45       apply\r\n4      61   authority\r\n5      64        away\r\n6      66        baby\r\n7      79      beauty\r\n8     102        body\r\n9     108         box\r\n10    109         boy\r\n11    120        busy\r\n12    122         buy\r\n13    123          by\r\n14    130       carry\r\n15    153        city\r\n16    175   community\r\n17    176     company\r\n18    191        copy\r\n19    198     country\r\n20    199      county\r\n21    212         day\r\n22    249         dry\r\n23    253       early\r\n24    255        easy\r\n25    257     economy\r\n26    267      employ\r\n27    272       enjoy\r\n28    282       every\r\n29    301      family\r\n30    328         fly\r\n31    341      friday\r\n32    355     germany\r\n33    373         guy\r\n34    380       happy\r\n35    390       heavy\r\n36    395     history\r\n37    398     holiday\r\n38    413    identify\r\n39    424    industry\r\n40    444         key\r\n41    454        lady\r\n42    462         lay\r\n43    476      likely\r\n44    503        many\r\n45    506       marry\r\n46    509         may\r\n47    529      monday\r\n48    530       money\r\n49    546   necessary\r\n50    573        okay\r\n51    578        only\r\n52    581 opportunity\r\n53    604       party\r\n54    607         pay\r\n55    623        play\r\n56    628      policy\r\n57    643      pretty\r\n58    665     quality\r\n59    679       ready\r\n60    682      really\r\n61    721    saturday\r\n62    723         say\r\n63    731   secretary\r\n64    747         sex\r\n65    772         six\r\n66    781     society\r\n67    785       sorry\r\n68    805        stay\r\n69    810       story\r\n70    812    strategy\r\n71    818       study\r\n72    829      sunday\r\n73    830      supply\r\n74    841         tax\r\n75    859        they\r\n76    863      thirty\r\n77    871    thursday\r\n78    875       today\r\n79    895         try\r\n80    896     tuesday\r\n81    899      twenty\r\n82    907  university\r\n83    916        very\r\n84    933         way\r\n85    936   wednesday\r\n86    952         why\r\n87    969       worry\r\n88    977   yesterday\r\n\r\n\r\n\r\ntb %>% \r\n    dplyr::mutate(\r\n        vowels = str_count(words, \"[aeiou]\"),\r\n        consonent = str_count(words, \"[^aeiou]\")\r\n    )%>% \r\n    tail(10)\r\n\r\n\r\n    seriel      word vowels consonent\r\n971    971     worth      1         4\r\n972    972     would      2         3\r\n973    973     write      2         3\r\n974    974     wrong      1         4\r\n975    975      year      2         2\r\n976    976       yes      1         2\r\n977    977 yesterday      3         6\r\n978    978       yet      1         2\r\n979    979       you      2         1\r\n980    980     young      2         3\r\n\r\n\r\n\r\nstr_view(str, \"[aeiou]\")\r\n\r\n\r\n\r\n{\"x\":{\"html\":\"<ul>\\n  <li><span class='match'>a<\\/span>pple<\\/li>\\n  <li>b<span class='match'>a<\\/span>nana<\\/li>\\n  <li>p<span class='match'>e<\\/span>ar<\\/li>\\n<\\/ul>\"},\"evals\":[],\"jsHooks\":[]}\r\nstr_view_all(str, \"[aeiou]\")\r\n\r\n\r\n\r\n{\"x\":{\"html\":\"<ul>\\n  <li><span class='match'>a<\\/span>ppl<span class='match'>e<\\/span><\\/li>\\n  <li>b<span class='match'>a<\\/span>n<span class='match'>a<\\/span>n<span class='match'>a<\\/span><\\/li>\\n  <li>p<span class='match'>e<\\/span><span class='match'>a<\\/span>r<\\/li>\\n<\\/ul>\"},\"evals\":[],\"jsHooks\":[]}\r\n\r\n\r\ntail(sentences)\r\n\r\n\r\n[1] \"Small children came to see him.\"        \r\n[2] \"The grass and bushes were wet with dew.\"\r\n[3] \"The blind man counted his old coins.\"   \r\n[4] \"A severe storm tore down the barn.\"     \r\n[5] \"She called his name many times.\"        \r\n[6] \"When you hear the bell, come quickly.\"  \r\n\r\n\r\n\r\ncolor <- c(' red', 'blue', 'green', 'yellow', 'purple', 'orange', 'brown')\r\nv <- str_c(color, collapse = \"|\")\r\n\r\nstr_view(str_subset(sentences, v), v)\r\n\r\n\r\n\r\n{\"x\":{\"html\":\"<ul>\\n  <li>Glue the sheet to the dark <span class='match'>blue<\\/span> background.<\\/li>\\n  <li>Two <span class='match'>blue<\\/span> fish swam in the tank.<\\/li>\\n  <li>A wisp of cloud hung in the <span class='match'>blue<\\/span> air.<\\/li>\\n  <li>Leaves turn <span class='match'>brown<\\/span> and yellow in the fall.<\\/li>\\n  <li>The spot on the blotter was made by <span class='match'>green<\\/span> ink.<\\/li>\\n  <li>The sofa cushion is<span class='match'> red<\\/span> and of light weight.<\\/li>\\n  <li>The sky that morning was clear and bright <span class='match'>blue<\\/span>.<\\/li>\\n  <li>The <span class='match'>brown<\\/span> house was on fire to the attic.<\\/li>\\n  <li>A <span class='match'>blue<\\/span> crane is a tall wading bird.<\\/li>\\n  <li>It is hard to erase <span class='match'>blue<\\/span> or red ink.<\\/li>\\n  <li>The lamp shone with a steady <span class='match'>green<\\/span> flame.<\\/li>\\n  <li>The box is held by a bright<span class='match'> red<\\/span> snapper.<\\/li>\\n  <li>The houses are built of<span class='match'> red<\\/span> clay bricks.<\\/li>\\n  <li>Tea served from the <span class='match'>brown<\\/span> jug is tasty.<\\/li>\\n  <li>The<span class='match'> red<\\/span> tape bound the smuggled food.<\\/li>\\n  <li>Hedge apples may stain your hands <span class='match'>green<\\/span>.<\\/li>\\n  <li>The plant grew large and <span class='match'>green<\\/span> in the window.<\\/li>\\n  <li>The <span class='match'>purple<\\/span> tie was ten years old.<\\/li>\\n  <li>Bathe and relax in the cool <span class='match'>green<\\/span> grass.<\\/li>\\n  <li>The lake sparkled in the<span class='match'> red<\\/span> hot sun.<\\/li>\\n  <li>Mark the spot with a sign painted<span class='match'> red<\\/span>.<\\/li>\\n  <li>The couch cover and hall drapes were <span class='match'>blue<\\/span>.<\\/li>\\n  <li>A man in a <span class='match'>blue<\\/span> sweater sat at the desk.<\\/li>\\n  <li>The small<span class='match'> red<\\/span> neon lamp went out.<\\/li>\\n  <li>A <span class='match'>brown<\\/span> leather bag hung from its strap.<\\/li>\\n  <li>Paint the sockets in the wall dull <span class='match'>green<\\/span>.<\\/li>\\n  <li>Wake and rise, and step into the <span class='match'>green<\\/span> outdoors.<\\/li>\\n  <li>The <span class='match'>green<\\/span> light in the brown box flickered.<\\/li>\\n  <li>The farmer swapped his horse for a <span class='match'>brown<\\/span> ox.<\\/li>\\n  <li>Tear a thin sheet from the <span class='match'>yellow<\\/span> pad.<\\/li>\\n  <li>The sky in the west is tinged with <span class='match'>orange<\\/span> red.<\\/li>\\n  <li>The<span class='match'> red<\\/span> paper brightened the dim stage.<\\/li>\\n  <li>The hail pattered on the burnt <span class='match'>brown<\\/span> grass.<\\/li>\\n  <li>The big<span class='match'> red<\\/span> apple fell to the ground.<\\/li>\\n<\\/ul>\"},\"evals\":[],\"jsHooks\":[]}\r\nstr_view_all(str_subset(sentences, v), v)\r\n\r\n\r\n\r\n{\"x\":{\"html\":\"<ul>\\n  <li>Glue the sheet to the dark <span class='match'>blue<\\/span> background.<\\/li>\\n  <li>Two <span class='match'>blue<\\/span> fish swam in the tank.<\\/li>\\n  <li>A wisp of cloud hung in the <span class='match'>blue<\\/span> air.<\\/li>\\n  <li>Leaves turn <span class='match'>brown<\\/span> and <span class='match'>yellow<\\/span> in the fall.<\\/li>\\n  <li>The spot on the blotter was made by <span class='match'>green<\\/span> ink.<\\/li>\\n  <li>The sofa cushion is<span class='match'> red<\\/span> and of light weight.<\\/li>\\n  <li>The sky that morning was clear and bright <span class='match'>blue<\\/span>.<\\/li>\\n  <li>The <span class='match'>brown<\\/span> house was on fire to the attic.<\\/li>\\n  <li>A <span class='match'>blue<\\/span> crane is a tall wading bird.<\\/li>\\n  <li>It is hard to erase <span class='match'>blue<\\/span> or<span class='match'> red<\\/span> ink.<\\/li>\\n  <li>The lamp shone with a steady <span class='match'>green<\\/span> flame.<\\/li>\\n  <li>The box is held by a bright<span class='match'> red<\\/span> snapper.<\\/li>\\n  <li>The houses are built of<span class='match'> red<\\/span> clay bricks.<\\/li>\\n  <li>Tea served from the <span class='match'>brown<\\/span> jug is tasty.<\\/li>\\n  <li>The<span class='match'> red<\\/span> tape bound the smuggled food.<\\/li>\\n  <li>Hedge apples may stain your hands <span class='match'>green<\\/span>.<\\/li>\\n  <li>The plant grew large and <span class='match'>green<\\/span> in the window.<\\/li>\\n  <li>The <span class='match'>purple<\\/span> tie was ten years old.<\\/li>\\n  <li>Bathe and relax in the cool <span class='match'>green<\\/span> grass.<\\/li>\\n  <li>The lake sparkled in the<span class='match'> red<\\/span> hot sun.<\\/li>\\n  <li>Mark the spot with a sign painted<span class='match'> red<\\/span>.<\\/li>\\n  <li>The couch cover and hall drapes were <span class='match'>blue<\\/span>.<\\/li>\\n  <li>A man in a <span class='match'>blue<\\/span> sweater sat at the desk.<\\/li>\\n  <li>The small<span class='match'> red<\\/span> neon lamp went out.<\\/li>\\n  <li>A <span class='match'>brown<\\/span> leather bag hung from its strap.<\\/li>\\n  <li>Paint the sockets in the wall dull <span class='match'>green<\\/span>.<\\/li>\\n  <li>Wake and rise, and step into the <span class='match'>green<\\/span> outdoors.<\\/li>\\n  <li>The <span class='match'>green<\\/span> light in the <span class='match'>brown<\\/span> box flickered.<\\/li>\\n  <li>The farmer swapped his horse for a <span class='match'>brown<\\/span> ox.<\\/li>\\n  <li>Tear a thin sheet from the <span class='match'>yellow<\\/span> pad.<\\/li>\\n  <li>The sky in the west is tinged with <span class='match'>orange<\\/span><span class='match'> red<\\/span>.<\\/li>\\n  <li>The<span class='match'> red<\\/span> paper brightened the dim stage.<\\/li>\\n  <li>The hail pattered on the burnt <span class='match'>brown<\\/span> grass.<\\/li>\\n  <li>The big<span class='match'> red<\\/span> apple fell to the ground.<\\/li>\\n<\\/ul>\"},\"evals\":[],\"jsHooks\":[]}\r\nstr_view(sentences[str_count(sentences, v)>1], v)\r\n\r\n\r\n\r\n{\"x\":{\"html\":\"<ul>\\n  <li>Leaves turn <span class='match'>brown<\\/span> and yellow in the fall.<\\/li>\\n  <li>It is hard to erase <span class='match'>blue<\\/span> or red ink.<\\/li>\\n  <li>The <span class='match'>green<\\/span> light in the brown box flickered.<\\/li>\\n  <li>The sky in the west is tinged with <span class='match'>orange<\\/span> red.<\\/li>\\n<\\/ul>\"},\"evals\":[],\"jsHooks\":[]}\r\nstr_view_all(sentences[str_count(sentences, v)>1], v)\r\n\r\n\r\n\r\n{\"x\":{\"html\":\"<ul>\\n  <li>Leaves turn <span class='match'>brown<\\/span> and <span class='match'>yellow<\\/span> in the fall.<\\/li>\\n  <li>It is hard to erase <span class='match'>blue<\\/span> or<span class='match'> red<\\/span> ink.<\\/li>\\n  <li>The <span class='match'>green<\\/span> light in the <span class='match'>brown<\\/span> box flickered.<\\/li>\\n  <li>The sky in the west is tinged with <span class='match'>orange<\\/span><span class='match'> red<\\/span>.<\\/li>\\n<\\/ul>\"},\"evals\":[],\"jsHooks\":[]}\r\nSplitting\r\n\r\n\r\nsentences %>% \r\n    head() %>% \r\n    str_split(\" \")\r\n\r\n\r\n[[1]]\r\n[1] \"The\"     \"birch\"   \"canoe\"   \"slid\"    \"on\"      \"the\"    \r\n[7] \"smooth\"  \"planks.\"\r\n\r\n[[2]]\r\n[1] \"Glue\"        \"the\"         \"sheet\"       \"to\"         \r\n[5] \"the\"         \"dark\"        \"blue\"        \"background.\"\r\n\r\n[[3]]\r\n[1] \"It's\"  \"easy\"  \"to\"    \"tell\"  \"the\"   \"depth\" \"of\"    \"a\"    \r\n[9] \"well.\"\r\n\r\n[[4]]\r\n[1] \"These\"   \"days\"    \"a\"       \"chicken\" \"leg\"     \"is\"     \r\n[7] \"a\"       \"rare\"    \"dish.\"  \r\n\r\n[[5]]\r\n[1] \"Rice\"   \"is\"     \"often\"  \"served\" \"in\"     \"round\"  \"bowls.\"\r\n\r\n[[6]]\r\n[1] \"The\"    \"juice\"  \"of\"     \"lemons\" \"makes\"  \"fine\"   \"punch.\"\r\n\r\nsentences %>% \r\n    head() %>% \r\n    str_split(\" \", simplify = TRUE)\r\n\r\n\r\n     [,1]    [,2]    [,3]    [,4]      [,5]    [,6]    [,7]    \r\n[1,] \"The\"   \"birch\" \"canoe\" \"slid\"    \"on\"    \"the\"   \"smooth\"\r\n[2,] \"Glue\"  \"the\"   \"sheet\" \"to\"      \"the\"   \"dark\"  \"blue\"  \r\n[3,] \"It's\"  \"easy\"  \"to\"    \"tell\"    \"the\"   \"depth\" \"of\"    \r\n[4,] \"These\" \"days\"  \"a\"     \"chicken\" \"leg\"   \"is\"    \"a\"     \r\n[5,] \"Rice\"  \"is\"    \"often\" \"served\"  \"in\"    \"round\" \"bowls.\"\r\n[6,] \"The\"   \"juice\" \"of\"    \"lemons\"  \"makes\" \"fine\"  \"punch.\"\r\n     [,8]          [,9]   \r\n[1,] \"planks.\"     \"\"     \r\n[2,] \"background.\" \"\"     \r\n[3,] \"a\"           \"well.\"\r\n[4,] \"rare\"        \"dish.\"\r\n[5,] \"\"            \"\"     \r\n[6,] \"\"            \"\"     \r\n\r\n\r\n\r\nbanana <- c(\"Banana\", \"banana\", \"BANANA\")\r\n\r\nstr_view(banana, \"banana\")\r\n\r\n\r\n\r\n{\"x\":{\"html\":\"<ul>\\n  <li>Banana<\\/li>\\n  <li><span class='match'>banana<\\/span><\\/li>\\n  <li>BANANA<\\/li>\\n<\\/ul>\"},\"evals\":[],\"jsHooks\":[]}\r\n\r\n\r\nstr_view(banana, regex(\"banana\", ignore_case = TRUE))\r\n\r\n\r\n\r\n{\"x\":{\"html\":\"<ul>\\n  <li><span class='match'>Banana<\\/span><\\/li>\\n  <li><span class='match'>banana<\\/span><\\/li>\\n  <li><span class='match'>BANANA<\\/span><\\/li>\\n<\\/ul>\"},\"evals\":[],\"jsHooks\":[]}\r\n\r\n\r\n\r\n",
      "last_modified": "2022-02-16T13:01:36+05:30"
    },
    {
      "path": "tidy.html",
      "title": "Tidy: Art of Data Manipulation",
      "author": [],
      "contents": "\r\nInstalling & calling the library in the environment to use\r\n\r\n\r\n#install.packages('tidyr')\r\n\r\nlibrary(tidyr)\r\nlibrary(dplyr)\r\n\r\npackageVersion('tidyr')\r\n\r\n\r\n[1] '1.1.4'\r\n\r\nData frame creation to be used further in the analysis and exploration. Again, we are using set.seed() function in order to keep our sample values to be same, hence ultimately data frame to be same.\r\n\r\n\r\nset.seed(123)\r\n\r\ndf <- data.frame(\r\n  id = 1:100,\r\n  X = sample(130:150, 100, TRUE),\r\n  Z = sample(100:150, 100, TRUE)\r\n) %>% \r\n  glimpse()\r\n\r\n\r\nRows: 100\r\nColumns: 3\r\n$ id <int> 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17~\r\n$ X  <int> 144, 148, 143, 132, 139, 147, 140, 134, 149, 143, 134, 14~\r\n$ Z  <int> 122, 125, 137, 145, 131, 106, 126, 141, 104, 105, 115, 12~\r\n\r\n\r\n\r\ndf %>% \r\n  gather(key = Type, value = Value, X:Z) %>% \r\n  head()\r\n\r\n\r\n  id Type Value\r\n1  1    X   144\r\n2  2    X   148\r\n3  3    X   143\r\n4  4    X   132\r\n5  5    X   139\r\n6  6    X   147\r\n\r\n\r\n\r\nset.seed(123)\r\n\r\ndf1 <- data.frame(\r\n  id = 1:50,\r\n  stage = sample(c('A', 'B'), 50, replace = TRUE, prob = c(.8, .2)),\r\n  Q1_2020 = 100*rnorm(50),\r\n  Q2_2020 = 95*rnorm(50),\r\n  Q3_2020 = 98*rnorm(50),\r\n  Q4_2020 = 93*rnorm(50),\r\n  Q1_2021 = 100*rnorm(50),\r\n  Q2_2021 = 91*rnorm(50),\r\n  Q3_2021 = 94*rnorm(50),\r\n  Q4_2021 = 90*rnorm(50)\r\n)\r\n\r\n\r\ndf1 %>% \r\n  gather(key = Quarter, value = Value, Q1_2020:Q4_2021) %>% \r\n  head(8)\r\n\r\n\r\n  id stage Quarter      Value\r\n1  1     A Q1_2020 -168.66933\r\n2  2     A Q1_2020   83.77870\r\n3  3     A Q1_2020   15.33731\r\n4  4     B Q1_2020 -113.81369\r\n5  5     B Q1_2020  125.38149\r\n6  6     A Q1_2020   42.64642\r\n7  7     A Q1_2020  -29.50715\r\n8  8     B Q1_2020   89.51257\r\n\r\n\r\n\r\ndf2 <- df1 %>% \r\n  gather(key = Quarter, value = Value, Q1_2020:Q4_2021) %>% \r\n  separate(Quarter, into = c('Quarter', 'Year'), sep = '_')\r\n\r\ndf2 %>% \r\n  tail(10)\r\n\r\n\r\n    id stage Quarter Year       Value\r\n391 41     A      Q4 2021 -237.883406\r\n392 42     A      Q4 2021   -8.364692\r\n393 43     A      Q4 2021   38.725623\r\n394 44     A      Q4 2021   48.185896\r\n395 45     A      Q4 2021  -49.975052\r\n396 46     A      Q4 2021  160.155262\r\n397 47     A      Q4 2021   25.778198\r\n398 48     A      Q4 2021   11.368427\r\n399 49     A      Q4 2021  114.504010\r\n400 50     B      Q4 2021  -64.661960\r\n\r\n\r\n\r\ndf3 <- \r\n        df2 %>% \r\n          cbind(df3 = runif(400, 5, 50)) %>% \r\n          pivot_wider(names_from = c(Quarter, Year),\r\n                      values_from = c(Value, df3)\r\n              ) \r\ndf3 %>% \r\n  glimpse()\r\n\r\n\r\nRows: 50\r\nColumns: 18\r\n$ id            <int> 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14,~\r\n$ stage         <chr> \"A\", \"A\", \"A\", \"B\", \"B\", \"A\", \"A\", \"B\", \"A\", \"~\r\n$ Value_Q1_2020 <dbl> -168.669331, 83.778704, 15.337312, -113.813694~\r\n$ Value_Q2_2020 <dbl> 97.4292801, -27.0534357, -115.9681827, 17.2238~\r\n$ Value_Q3_2020 <dbl> -63.891090, 23.067884, 7.640163, -94.261950, -~\r\n$ Value_Q4_2020 <dbl> -101.927653, 3.514321, 28.874710, 40.596684, -~\r\n$ Value_Q1_2021 <dbl> 5.974994, -70.459646, -71.721816, 88.465050, -~\r\n$ Value_Q2_2021 <dbl> -40.636707, 15.907046, 6.784157, 38.963176, 2.~\r\n$ Value_Q3_2021 <dbl> 64.2720791, -5.7172637, 59.4983070, 125.538655~\r\n$ Value_Q4_2021 <dbl> -53.053293, -89.710267, 13.002813, -1.287667, ~\r\n$ df3_Q1_2020   <dbl> 19.680492, 37.687950, 49.628536, 37.181009, 27~\r\n$ df3_Q2_2020   <dbl> 46.566465, 29.416927, 43.356407, 31.260329, 35~\r\n$ df3_Q3_2020   <dbl> 30.212624, 12.014337, 48.046089, 6.978498, 21.~\r\n$ df3_Q4_2020   <dbl> 17.313023, 31.724012, 12.208317, 43.404361, 43~\r\n$ df3_Q1_2021   <dbl> 36.89849, 42.20220, 45.13533, 29.27348, 29.989~\r\n$ df3_Q2_2021   <dbl> 41.041303, 37.749322, 14.767159, 38.490733, 43~\r\n$ df3_Q3_2021   <dbl> 46.159573, 31.960219, 38.732319, 46.352964, 28~\r\n$ df3_Q4_2021   <dbl> 43.636613, 44.932314, 27.009117, 37.314131, 26~\r\n\r\n\r\n\r\ndf3 %>% \r\n  pivot_longer(names_to = 'type', values_to = 'value', \r\n               cols = Value_Q1_2020:df3_Q4_2021) %>% \r\n  head(10)\r\n\r\n\r\n# A tibble: 10 x 4\r\n      id stage type            value\r\n   <int> <chr> <chr>           <dbl>\r\n 1     1 A     Value_Q1_2020 -169.  \r\n 2     1 A     Value_Q2_2020   97.4 \r\n 3     1 A     Value_Q3_2020  -63.9 \r\n 4     1 A     Value_Q4_2020 -102.  \r\n 5     1 A     Value_Q1_2021    5.97\r\n 6     1 A     Value_Q2_2021  -40.6 \r\n 7     1 A     Value_Q3_2021   64.3 \r\n 8     1 A     Value_Q4_2021  -53.1 \r\n 9     1 A     df3_Q1_2020     19.7 \r\n10     1 A     df3_Q2_2020     46.6 \r\n\r\n\r\n\r\ndf3 %>% \r\n  pivot_longer(names_to = 'type', values_to = 'value', \r\n               cols = Value_Q1_2020:df3_Q4_2021) %>% \r\n  separate(type, c('category', 'quarter', 'year'), '_') %>% \r\n  glimpse()\r\n\r\n\r\nRows: 800\r\nColumns: 6\r\n$ id       <int> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, ~\r\n$ stage    <chr> \"A\", \"A\", \"A\", \"A\", \"A\", \"A\", \"A\", \"A\", \"A\", \"A\", \"~\r\n$ category <chr> \"Value\", \"Value\", \"Value\", \"Value\", \"Value\", \"Value~\r\n$ quarter  <chr> \"Q1\", \"Q2\", \"Q3\", \"Q4\", \"Q1\", \"Q2\", \"Q3\", \"Q4\", \"Q1~\r\n$ year     <chr> \"2020\", \"2020\", \"2020\", \"2020\", \"2021\", \"2021\", \"20~\r\n$ value    <dbl> -168.669331, 97.429280, -63.891090, -101.927653, 5.~\r\n\r\n\r\n\r\n\r\n",
      "last_modified": "2022-02-16T13:01:39+05:30"
    },
    {
      "path": "tidymod.html",
      "title": "TIDYMODELS",
      "author": [],
      "contents": "\r\n“CAREER”\r\n\r\n\r\n\r\nPACKAGES IN USE\r\n\r\n\r\n#install.packages('tidymodels')\r\nlibrary(tidymodels)\r\nlibrary(tidyverse)\r\nlibrary(discrim)\r\n\r\n\r\n\r\nAn auto-insurance company is revamping its pricing model. The analyst developing the new price model believes that the best approach is to develop 2 models: one for customers who are likely to file an insurance claim within the first year of their contract and another one for all other customers. The analyst has prepared a clean dataset consisting of 10,000 customers and 10 engineered features which capture driving behavior. The data has already been preprocessed for you (i.e., no missing data, no outliers, data is scaled, no correlated features, and the classes are fairly balanced). The data is contained in claim_prediction.csv , where CLAIM = 1 means the customer filed a claim in the first year and CLAIM = 0 means the customer did not. Develop a model to predict if customers will file a claim in their first year based on their driving behavior. In addition to submitting your code, use comments to explain the decisions you made and how well you expect this model to perform on new data from a similar customer pool (and why). Note that you are being evaluated on your model building and validation workflow, rather than on the complexity of your solution.\r\nIMPORT & FEATURE ENCODING\r\n\r\n\r\ndb_file <- readRDS('data/db_file.RDS')\r\n\r\ndb_file$CLAIM <- as.factor(db_file$CLAIM)\r\n\r\n\r\n\r\nDATA SPLITTING\r\n\r\n\r\nset.seed(123)\r\nsplit <- initial_split(db_file, strata = CLAIM, prop = 4/5)\r\n\r\ntrain_claim <- training(split)\r\ntrain_fold <- vfold_cv(train_claim)\r\n\r\n\r\ntest_claim <- testing(split)\r\n\r\n\r\n\r\nModeling\r\nLDA {Linear Discriminant Analysis}\r\n\r\n\r\ntidy_lda <- discrim_linear() %>% \r\n  set_engine('MASS') %>% \r\n  fit(CLAIM ~ ., data = train_claim)\r\n\r\n\r\n(tidy_lda)\r\n\r\n\r\nparsnip model object\r\n\r\nFit time:  131ms \r\nCall:\r\nlda(CLAIM ~ ., data = data)\r\n\r\nPrior probabilities of groups:\r\n        0         1 \r\n0.5051881 0.4948119 \r\n\r\nGroup means:\r\n       EADDC      EAFXA     FDDBC     AFDDA       AXCXA    EXCCE\r\n0 -0.1736588 -1.3273253  1.165295 0.1644013 -0.04543404 0.196698\r\n1 -1.3781192 -0.1560515 -1.164216 1.3920122 -0.04405898 1.325212\r\n       FBXFC      DFFEC        CEXAE      BBADX\r\n0 0.07028969 -1.3227406 -0.027163132 0.07381984\r\n1 0.01296680 -0.1780381 -0.009079098 1.34710730\r\n\r\nCoefficients of linear discriminants:\r\n              LD1\r\nEADDC -0.11711552\r\nEAFXA  0.03094703\r\nFDDBC -0.35652596\r\nAFDDA  0.19226349\r\nAXCXA  0.10191197\r\nEXCCE  0.06935853\r\nFBXFC  0.04442671\r\nDFFEC  0.13263830\r\nCEXAE  0.12538650\r\nBBADX  0.11377118\r\n\r\nQDA {Quadratic Discriminant Analysis}\r\n\r\n\r\ntidy_qda <- discrim_quad() %>% \r\n  set_mode('classification') %>% \r\n  set_engine('MASS') %>% \r\n  fit(CLAIM ~ ., data = train_claim)\r\n\r\n\r\ntidy_qda\r\n\r\n\r\nparsnip model object\r\n\r\nFit time:  11ms \r\nCall:\r\nqda(CLAIM ~ ., data = data)\r\n\r\nPrior probabilities of groups:\r\n        0         1 \r\n0.5051881 0.4948119 \r\n\r\nGroup means:\r\n       EADDC      EAFXA     FDDBC     AFDDA       AXCXA    EXCCE\r\n0 -0.1736588 -1.3273253  1.165295 0.1644013 -0.04543404 0.196698\r\n1 -1.3781192 -0.1560515 -1.164216 1.3920122 -0.04405898 1.325212\r\n       FBXFC      DFFEC        CEXAE      BBADX\r\n0 0.07028969 -1.3227406 -0.027163132 0.07381984\r\n1 0.01296680 -0.1780381 -0.009079098 1.34710730\r\n\r\nGLM {LOGISTIC REGRESSION}\r\n\r\n\r\nlogit_spec <- logistic_reg() %>% \r\n  set_mode(\"classification\") %>% \r\n  set_engine('glm') \r\n\r\n\r\n\r\n\r\n\r\nclaim_wf <- workflow() %>% \r\n  add_formula(CLAIM ~ .)\r\n\r\n\r\n\r\n\r\n\r\nlogit_result <- claim_wf %>% \r\n  add_model(logit_spec) %>% \r\n  fit_resamples(\r\n    resamples = train_fold,\r\n    control = control_resamples(save_pred = TRUE, verbose = FALSE)\r\n  )\r\n\r\n\r\n\r\n\r\n\r\n# logit_result %>% \r\n#   collect_predictions() %>% \r\n#   group_by(id) %>% \r\n#   roc_curve(CLAIM, .pred_0) %>% \r\n#   autoplot()\r\n\r\n# Or\r\n\r\nlogit_result %>% \r\n  collect_predictions() %>% \r\n  group_by(id) %>% \r\n  roc_curve(CLAIM, .pred_0) %>% \r\n  ggplot(aes(1 - specificity, sensitivity, color = id))+\r\n  geom_abline(lty = 2, color = 'grey70', size = 1.8)+\r\n  geom_path(show.legend = FALSE, alpha = 0.6, size = 1.2)+\r\n  coord_equal()\r\n\r\n\r\n\r\n\r\nhyperparameter tuneable Models\r\n\r\n\r\n\r\n",
      "last_modified": "2022-02-16T13:01:41+05:30"
    }
  ],
  "collections": []
}
